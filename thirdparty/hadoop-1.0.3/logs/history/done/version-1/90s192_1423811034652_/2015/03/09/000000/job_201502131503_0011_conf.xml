<?xml version="1.0" encoding="UTF-8" standalone="no"?><configuration>
<property><name>mapred.jobtracker.maxtasks.per.job</name><value>-1</value></property>
<property><name>hive.metastore.schema.verification</name><value>false</value></property>
<property><name>hive.exec.job.debug.capture.stacktraces</name><value>true</value></property>
<property><name>hive.exec.orc.memory.pool</name><value>0.5</value></property>
<property><name>mapred.line.input.format.linespermap</name><value>1</value></property>
<property><name>mapred.system.dir</name><value>${hadoop.tmp.dir}/mapred/system</value></property>
<property><name>mapred.min.split.size.per.node</name><value>1</value></property>
<property><name>hive.stats.reliable</name><value>false</value></property>
<property><name>hive.exec.check.crossproducts</name><value>true</value></property>
<property><name>dfs.namenode.delegation.token.renew-interval</name><value>86400000</value></property>
<property><name>hive.metastore.connect.retries</name><value>5</value></property>
<property><name>mapreduce.job.complete.cancel.delegation.tokens</name><value>true</value></property>
<property><name>hive.auto.progress.timeout</name><value>0</value></property>
<property><name>hive.hmshandler.retry.interval</name><value>1000</value></property>
<property><name>datanucleus.storeManagerType</name><value>rdbms</value></property>
<property><name>javax.jdo.option.NonTransactionalRead</name><value>true</value></property>
<property><name>hive.insert.into.external.tables</name><value>true</value></property>
<property><name>hive.exec.default.partition.name</name><value>__HIVE_DEFAULT_PARTITION__</value></property>
<property><name>dfs.namenode.logging.level</name><value>info</value></property>
<property><name>hive.metastore.execute.setugi</name><value>false</value></property>
<property><name>hive.fetch.task.conversion</name><value>minimal</value></property>
<property><name>hive.join.cache.size</name><value>25000</value></property>
<property><name>mapred.input.format.class</name><value>org.apache.hadoop.hive.ql.io.CombineHiveInputFormat</value></property>
<property><name>hive.enforce.sorting</name><value>false</value></property>
<property><name>hive.zookeeper.session.timeout</name><value>600000</value></property>
<property><name>mapred.reduce.max.attempts</name><value>4</value></property>
<property><name>io.mapfile.bloom.error.rate</name><value>0.005</value></property>
<property><name>hive.mapred.mode</name><value>nonstrict</value></property>
<property><name>mapred.tasktracker.map.tasks.maximum</name><value>4</value></property>
<property><name>hive.stats.deserialization.factor</name><value>1.0</value></property>
<property><name>hive.lock.manager</name><value>org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager</value></property>
<property><name>mapred.local.dir.minspacekill</name><value>0</value></property>
<property><name>hive.limit.optimize.enable</name><value>false</value></property>
<property><name>hive.exec.orc.default.block.padding</name><value>true</value></property>
<property><name>hive.metastore.rawstore.impl</name><value>org.apache.hadoop.hive.metastore.ObjectStore</value></property>
<property><name>hive.exec.infer.bucket.sort.num.buckets.power.two</name><value>false</value></property>
<property><name>hive.optimize.sampling.orderby</name><value>false</value></property>
<property><name>hive.merge.current.job.concatenate.list.bucketing.depth</name><value>0</value></property>
<property><name>mapred.jobtracker.job.history.block.size</name><value>3145728</value></property>
<property><name>mapreduce.job.split.metainfo.maxsize</name><value>10000000</value></property>
<property><name>mapred.jobtracker.completeuserjobs.maximum</name><value>100</value></property>
<property><name>hive.orc.compute.splits.num.threads</name><value>10</value></property>
<property><name>mapreduce.job.committer.task.cleanup.needed</name><value>false</value></property>
<property><name>dfs.name.edits.dir</name><value>${dfs.name.dir}</value></property>
<property><name>hive.server2.enable.doAs</name><value>true</value></property>
<property><name>hive.querylog.location</name><value>/tmp/${user.name}</value></property>
<property><name>mapred.task.timeout</name><value>600000</value></property>
<property><name>ipc.client.connection.maxidletime</name><value>10000</value></property>
<property><name>mapred.mapoutput.key.class</name><value>org.apache.hadoop.hive.ql.io.HiveKey</value></property>
<property><name>mapred.task.tracker.task-controller</name><value>org.apache.hadoop.mapred.DefaultTaskController</value></property>
<property><name>hive.lockmgr.zookeeper.default.partition.name</name><value>__HIVE_DEFAULT_ZOOKEEPER_PARTITION__</value></property>
<property><name>hive.convert.join.bucket.mapjoin.tez</name><value>false</value></property>
<property><name>hive.merge.mapredfiles</name><value>false</value></property>
<property><name>datanucleus.validateTables</name><value>false</value></property>
<property><name>hive.server2.tez.sessions.per.default.queue</name><value>1</value></property>
<property><name>mapred.local.dir.minspacestart</name><value>0</value></property>
<property><name>dfs.block.access.token.lifetime</name><value>600</value></property>
<property><name>hive.metastore.ds.retry.interval</name><value>1000</value></property>
<property><name>hive.metastore.client.connect.retry.delay</name><value>1</value></property>
<property><name>hive.exec.rcfile.use.sync.cache</name><value>true</value></property>
<property><name>hive.exec.orc.default.row.index.stride</name><value>10000</value></property>
<property><name>hive.metastore.archive.intermediate.original</name><value>_INTERMEDIATE_ORIGINAL</value></property>
<property><name>hive.script.auto.progress</name><value>false</value></property>
<property><name>hive.metastore.integral.jdo.pushdown</name><value>false</value></property>
<property><name>hive.metastore.disallow.incompatible.col.type.changes</name><value>false</value></property>
<property><name>hive.multi.insert.move.tasks.share.dependencies</name><value>false</value></property>
<property><name>hive.server2.tez.initialize.default.sessions</name><value>false</value></property>
<property><name>mapred.job.shuffle.merge.percent</name><value>0.66</value></property>
<property><name>hive.optimize.ppd.storage</name><value>true</value></property>
<property><name>hive.query.id</name><value>casa_20150309152424_cc80bb1e-b7f6-49b6-80c7-b0dde40761e1</value></property>
<property><name>dfs.block.size</name><value>67108864</value></property>
<property><name>hadoop.security.authentication</name><value>simple</value></property>
<property><name>fs.s3.sleepTimeSeconds</name><value>10</value></property>
<property><name>hive.script.serde</name><value>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</value></property>
<property><name>dfs.df.interval</name><value>60000</value></property>
<property><name>mapred.skip.reduce.max.skip.groups</name><value>0</value></property>
<property><name>hive.mapjoin.followby.gby.localtask.max.memory.usage</name><value>0.55</value></property>
<property><name>mapred.map.max.attempts</name><value>4</value></property>
<property><name>mapred.working.dir</name><value>hdfs://10.11.1.192:9000/user/casa</value></property>
<property><name>mapred.task.profile</name><value>false</value></property>
<property><name>fs.default.name</name><value>hdfs://10.11.1.192:9000</value></property>
<property><name>mapreduce.job.counters.limit</name><value>120</value></property>
<property><name>hive.test.mode.samplefreq</name><value>32</value></property>
<property><name>mapred.cache.files</name><value>hdfs://10.11.1.192:9000/tmp/hive-casa/hive_2015-03-09_15-24-45_148_8355964799932482103-1/-mr-10007/404838c9-4fde-4ab8-b855-77e63ceda9ae/map.xml#map.xml,hdfs://10.11.1.192:9000/tmp/hive-casa/hive_2015-03-09_15-24-45_148_8355964799932482103-1/-mr-10007/404838c9-4fde-4ab8-b855-77e63ceda9ae/reduce.xml#reduce.xml</value></property>
<property><name>hive.in.test</name><value>false</value></property>
<property><name>mapred.child.tmp</name><value>./tmp</value></property>
<property><name>mapred.job.tracker</name><value>10.11.1.192:9001</value></property>
<property><name>datanucleus.autoCreateSchema</name><value>true</value></property>
<property><name>hive.stats.retries.max</name><value>0</value></property>
<property><name>hive.stats.autogather</name><value>true</value></property>
<property><name>hive.stats.collect.rawdatasize</name><value>true</value></property>
<property><name>datanucleus.autoStartMechanismMode</name><value>checked</value></property>
<property><name>hive.debug.localtask</name><value>false</value></property>
<property><name>dfs.replication.min</name><value>1</value></property>
<property><name>hive.exec.orc.dictionary.key.size.threshold</name><value>0.8</value></property>
<property><name>dfs.safemode.threshold.pct</name><value>0.999f</value></property>
<property><name>hive.stats.max.variable.length</name><value>100</value></property>
<property><name>fs.s3.buffer.dir</name><value>${hadoop.tmp.dir}/s3</value></property>
<property><name>mapred.min.split.size.per.rack</name><value>1</value></property>
<property><name>hive.stageid.rearrange</name><value>none</value></property>
<property><name>hive.optimize.bucketmapjoin.sortedmerge</name><value>false</value></property>
<property><name>mapred.partitioner.class</name><value>org.apache.hadoop.hive.ql.io.DefaultHivePartitioner</value></property>
<property><name>mapreduce.workflow.node.name</name><value>Stage-2</value></property>
<property><name>hive.security.command.whitelist</name><value>set,reset,dfs,add,delete</value></property>
<property><name>hive.index.compact.query.max.entries</name><value>10000000</value></property>
<property><name>hive.join.emit.interval</name><value>1000</value></property>
<property><name>dfs.https.client.keystore.resource</name><value>ssl-client.xml</value></property>
<property><name>hive.test.mode</name><value>false</value></property>
<property><name>hive.input.format</name><value>org.apache.hadoop.hive.ql.io.CombineHiveInputFormat</value></property>
<property><name>hive.metastore.server.max.threads</name><value>100000</value></property>
<property><name>mapred.output.format.class</name><value>org.apache.hadoop.hive.ql.io.HiveOutputFormatImpl</value></property>
<property><name>mapred.tasktracker.reduce.tasks.maximum</name><value>4</value></property>
<property><name>ipc.server.tcpnodelay</name><value>false</value></property>
<property><name>hive.default.fileformat</name><value>TextFile</value></property>
<property><name>hive.decode.partition.name</name><value>false</value></property>
<property><name>javax.jdo.option.Multithreaded</name><value>true</value></property>
<property><name>ipc.client.tcpnodelay</name><value>false</value></property>
<property><name>fs.s3.maxRetries</name><value>4</value></property>
<property><name>fs.ftp.impl</name><value>org.apache.hadoop.fs.ftp.FTPFileSystem</value></property>
<property><name>hive.metastore.server.min.threads</name><value>200</value></property>
<property><name>hive.localize.resource.wait.interval</name><value>5000</value></property>
<property><name>datanucleus.identifierFactory</name><value>datanucleus1</value></property>
<property><name>mapred.job.name</name><value>select count(*) from le...left16.a=right16.a(Stage-2)</value></property>
<property><name>hive.server2.async.exec.threads</name><value>100</value></property>
<property><name>hive.security.metastore.authenticator.manager</name><value>org.apache.hadoop.hive.ql.security.HadoopDefaultMetastoreAuthenticator</value></property>
<property><name>hive.map.groupby.sorted</name><value>false</value></property>
<property><name>hive.skewjoin.mapjoin.min.split</name><value>33554432</value></property>
<property><name>hive.user.install.directory</name><value>hdfs:///user/</value></property>
<property><name>mapred.userlog.limit.kb</name><value>0</value></property>
<property><name>mapred.reduce.tasks.speculative.execution</name><value>true</value></property>
<property><name>hive.file.max.footer</name><value>100</value></property>
<property><name>mapred.reduce.parallel.copies</name><value>5</value></property>
<property><name>mapred.job.reduce.memory.mb</name><value>-1</value></property>
<property><name>hive.index.compact.binary.search</name><value>true</value></property>
<property><name>hive.server2.async.exec.shutdown.timeout</name><value>10</value></property>
<property><name>hive.mapred.reduce.tasks.speculative.execution</name><value>true</value></property>
<property><name>datanucleus.validateConstraints</name><value>false</value></property>
<property><name>hadoop.native.lib</name><value>true</value></property>
<property><name>mapreduce.job.cache.files.visibilities</name><value>true,true</value></property>
<property><name>io.mapfile.bloom.size</name><value>1048576</value></property>
<property><name>hive.limit.optimize.fetch.max</name><value>50000</value></property>
<property><name>hive.merge.current.job.has.dynamic.partitions</name><value>false</value></property>
<property><name>mapred.skip.attempts.to.start.skipping</name><value>2</value></property>
<property><name>mapred.min.split.size</name><value>1</value></property>
<property><name>hive.exec.show.job.failure.debug.info</name><value>true</value></property>
<property><name>hive.variable.substitute</name><value>true</value></property>
<property><name>jobclient.output.filter</name><value>FAILED</value></property>
<property><name>hive.mapjoin.check.memory.rows</name><value>100000</value></property>
<property><name>hive.cli.errors.ignore</name><value>false</value></property>
<property><name>mapred.committer.job.setup.cleanup.needed</name><value>false</value></property>
<property><name>hive.exec.orc.default.stripe.size</name><value>268435456</value></property>
<property><name>hive.server2.thrift.min.worker.threads</name><value>5</value></property>
<property><name>hive.optimize.bucketmapjoin</name><value>false</value></property>
<property><name>hive.insert.into.multilevel.dirs</name><value>false</value></property>
<property><name>hive.server2.allow.user.substitution</name><value>true</value></property>
<property><name>dfs.max.objects</name><value>0</value></property>
<property><name>hive.stats.dbclass</name><value>fs</value></property>
<property><name>hive.prewarm.enabled</name><value>false</value></property>
<property><name>hive.query.string</name><value>select count(*) from left16 join right16 on left16.a=right16.a</value></property>
<property><name>hive.cluster.delegation.token.store.class</name><value>org.apache.hadoop.hive.thrift.MemoryTokenStore</value></property>
<property><name>hive.optimize.metadataonly</name><value>true</value></property>
<property><name>mapred.job.tracker.http.address</name><value>0.0.0.0:50030</value></property>
<property><name>hive.merge.smallfiles.avgsize</name><value>16000000</value></property>
<property><name>hive.exec.plan</name><value>hdfs://10.11.1.192:9000/tmp/hive-casa/hive_2015-03-09_15-24-45_148_8355964799932482103-1/-mr-10007/404838c9-4fde-4ab8-b855-77e63ceda9ae</value></property>
<property><name>hive.exec.reducers.max</name><value>999</value></property>
<property><name>hive.security.authorization.enabled</name><value>false</value></property>
<property><name>hive.server2.use.SSL</name><value>false</value></property>
<property><name>hive.exec.dynamic.partition.mode</name><value>strict</value></property>
<property><name>mapred.output.compress</name><value>false</value></property>
<property><name>dfs.datanode.dns.nameserver</name><value>default</value></property>
<property><name>hive.server2.thrift.sasl.qop</name><value>auth</value></property>
<property><name>webinterface.private.actions</name><value>false</value></property>
<property><name>hive.optimize.sampling.orderby.percent</name><value>0.1</value></property>
<property><name>hive.groupby.skewindata</name><value>false</value></property>
<property><name>hive.autogen.columnalias.prefix.includefuncname</name><value>false</value></property>
<property><name>mapred.tasktracker.expiry.interval</name><value>600000</value></property>
<property><name>hive.metastore.batch.retrieve.max</name><value>300</value></property>
<property><name>javax.jdo.option.DetachAllOnCommit</name><value>true</value></property>
<property><name>mapred.submit.replication</name><value>10</value></property>
<property><name>datanucleus.connectionPoolingType</name><value>BoneCP</value></property>
<property><name>hive.merge.mapfiles</name><value>true</value></property>
<property><name>datanucleus.plugin.pluginRegistryBundleCheck</name><value>LOG</value></property>
<property><name>dfs.replication.max</name><value>512</value></property>
<property><name>dfs.replication</name><value>2</value></property>
<property><name>hive.exec.max.dynamic.partitions.pernode</name><value>100</value></property>
<property><name>io.sort.record.percent</name><value>0.05</value></property>
<property><name>hive.metastore.sasl.enabled</name><value>false</value></property>
<property><name>mapred.jobtracker.taskScheduler</name><value>org.apache.hadoop.mapred.JobQueueTaskScheduler</value></property>
<property><name>hive.metastore.batch.retrieve.table.partition.max</name><value>1000</value></property>
<property><name>hive.exec.mode.local.auto</name><value>false</value></property>
<property><name>hive.server.tcp.keepalive</name><value>true</value></property>
<property><name>hive.orc.cache.stripe.details.size</name><value>10000</value></property>
<property><name>fs.webhdfs.impl</name><value>org.apache.hadoop.hdfs.web.WebHdfsFileSystem</value></property>
<property><name>hive.optimize.skewjoin.compiletime</name><value>false</value></property>
<property><name>hive.optimize.bucketingsorting</name><value>true</value></property>
<property><name>hive.orc.splits.include.file.footer</name><value>false</value></property>
<property><name>hive.txn.max.open.batch</name><value>1000</value></property>
<property><name>hive.exec.mode.local.auto.inputbytes.max</name><value>134217728</value></property>
<property><name>hive.zookeeper.client.port</name><value>2181</value></property>
<property><name>mapred.temp.dir</name><value>${hadoop.tmp.dir}/mapred/temp</value></property>
<property><name>mapred.tasktracker.taskmemorymanager.monitoring-interval</name><value>5000</value></property>
<property><name>mapred.output.key.class</name><value>org.apache.hadoop.io.Text</value></property>
<property><name>hive.optimize.reducededuplication</name><value>true</value></property>
<property><name>mapred.reduce.tasks</name><value>1</value></property>
<property><name>mapred.queue.default.acl-administer-jobs</name><value>*</value></property>
<property><name>hive.exec.perf.logger</name><value>org.apache.hadoop.hive.ql.log.PerfLogger</value></property>
<property><name>hive.compute.splits.in.am</name><value>true</value></property>
<property><name>mapred.output.compression.codec</name><value>org.apache.hadoop.io.compress.DefaultCodec</value></property>
<property><name>hive.transform.escape.input</name><value>false</value></property>
<property><name>mapreduce.tasktracker.outofband.heartbeat</name><value>false</value></property>
<property><name>hive.metastore.event.expiry.duration</name><value>0</value></property>
<property><name>hadoop.security.token.service.use_ip</name><value>true</value></property>
<property><name>mapred.userlog.retain.hours</name><value>24</value></property>
<property><name>hive.sample.seednumber</name><value>0</value></property>
<property><name>mapreduce.reduce.shuffle.maxfetchfailures</name><value>10</value></property>
<property><name>mapred.healthChecker.interval</name><value>60000</value></property>
<property><name>hive.stats.fetch.column.stats</name><value>false</value></property>
<property><name>hive.session.id</name><value>77db5baa-d12a-4b2f-a699-c67bd9bd051b</value></property>
<property><name>mapred.job.tracker.retiredjobs.cache.size</name><value>1000</value></property>
<property><name>javax.jdo.PersistenceManagerFactoryClass</name><value>org.datanucleus.api.jdo.JDOPersistenceManagerFactory</value></property>
<property><name>hive.limit.row.max.size</name><value>100000</value></property>
<property><name>hive.rpc.query.plan</name><value>false</value></property>
<property><name>mapred.skip.map.auto.incr.proc.count</name><value>true</value></property>
<property><name>hive.server2.authentication</name><value>NONE</value></property>
<property><name>hive.localize.resource.num.wait.attempts</name><value>5</value></property>
<property><name>mapred.max.tracker.failures</name><value>4</value></property>
<property><name>javax.jdo.option.ConnectionUserName</name><value>APP</value></property>
<property><name>hadoop.rpc.socket.factory.class.default</name><value>org.apache.hadoop.net.StandardSocketFactory</value></property>
<property><name>dfs.replication.considerLoad</name><value>true</value></property>
<property><name>hive.auto.convert.join</name><value>true</value></property>
<property><name>hive.stats.collect.scancols</name><value>false</value></property>
<property><name>hive.vectorized.groupby.checkinterval</name><value>100000</value></property>
<property><name>fs.hdfs.impl</name><value>org.apache.hadoop.hdfs.DistributedFileSystem</value></property>
<property><name>hive.mapred.supports.subdirectories</name><value>false</value></property>
<property><name>dfs.datanode.ipc.address</name><value>0.0.0.0:50020</value></property>
<property><name>hive.vectorized.groupby.maxentries</name><value>1000000</value></property>
<property><name>mapred.map.tasks</name><value>4</value></property>
<property><name>hive.mapred.local.mem</name><value>0</value></property>
<property><name>stream.stderr.reporter.prefix</name><value>reporter:</value></property>
<property><name>mapred.cluster.map.memory.mb</name><value>-1</value></property>
<property><name>hive.hashtable.loadfactor</name><value>0.75</value></property>
<property><name>mapred.acls.enabled</name><value>false</value></property>
<property><name>fs.hftp.impl</name><value>org.apache.hadoop.hdfs.HftpFileSystem</value></property>
<property><name>hive.ppd.recognizetransivity</name><value>true</value></property>
<property><name>mapred.reduce.slowstart.completed.maps</name><value>0.05</value></property>
<property><name>fs.har.impl</name><value>org.apache.hadoop.hive.shims.HiveHarFileSystem</value></property>
<property><name>mapred.job.tracker.handler.count</name><value>10</value></property>
<property><name>hive.resultset.use.unique.column.names</name><value>true</value></property>
<property><name>hive.exec.reducers.bytes.per.reducer</name><value>1000000000</value></property>
<property><name>datanucleus.cache.level2.type</name><value>SOFT</value></property>
<property><name>job.end.retry.attempts</name><value>0</value></property>
<property><name>hive.security.authorization.manager</name><value>org.apache.hadoop.hive.ql.security.authorization.DefaultHiveAuthorizationProvider</value></property>
<property><name>dfs.http.address</name><value>0.0.0.0:50070</value></property>
<property><name>mapred.jobtracker.blacklist.fault-timeout-window</name><value>180</value></property>
<property><name>hive.exec.orc.skip.corrupt.data</name><value>false</value></property>
<property><name>hive.variable.substitute.depth</name><value>40</value></property>
<property><name>hive.merge.input.format.block.level</name><value>org.apache.hadoop.hive.ql.io.rcfile.merge.RCFileBlockMergeInputFormat</value></property>
<property><name>mapred.job.tracker.persist.jobstatus.dir</name><value>/jobtracker/jobsInfo</value></property>
<property><name>hive.stats.key.prefix.reserve.length</name><value>24</value></property>
<property><name>hive.exec.max.created.files</name><value>100000</value></property>
<property><name>hive.map.aggr</name><value>true</value></property>
<property><name>hive.querylog.enable.plan.progress</name><value>true</value></property>
<property><name>hive.support.concurrency</name><value>false</value></property>
<property><name>dfs.namenode.decommission.nodes.per.interval</name><value>5</value></property>
<property><name>hive.stats.join.factor</name><value>1.1</value></property>
<property><name>fs.file.impl</name><value>org.apache.hadoop.fs.LocalFileSystem</value></property>
<property><name>dfs.https.address</name><value>0.0.0.0:50470</value></property>
<property><name>hive.conf.restricted.list</name><value>hive.security.authenticator.manager,hive.security.authorization.manager</value></property>
<property><name>hive.txn.timeout</name><value>300</value></property>
<property><name>hive.metastore.authorization.storage.checks</name><value>false</value></property>
<property><name>hive.cli.print.header</name><value>false</value></property>
<property><name>hive.merge.rcfile.block.level</name><value>true</value></property>
<property><name>hive.fetch.task.aggr</name><value>false</value></property>
<property><name>mapreduce.reduce.shuffle.read.timeout</name><value>180000</value></property>
<property><name>hive.metastore.client.socket.timeout</name><value>20</value></property>
<property><name>hive.udtf.auto.progress</name><value>false</value></property>
<property><name>ipc.client.connect.max.retries</name><value>10</value></property>
<property><name>io.seqfile.lazydecompress</name><value>true</value></property>
<property><name>hive.limit.query.max.table.partition</name><value>-1</value></property>
<property><name>io.file.buffer.size</name><value>4096</value></property>
<property><name>hive.metastore.force.reload.conf</name><value>false</value></property>
<property><name>hive.exec.infer.bucket.sort</name><value>false</value></property>
<property><name>hive.serdes.using.metastore.for.schema</name><value>org.apache.hadoop.hive.ql.io.orc.OrcSerde,org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe,org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe,org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe,org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe,org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe,org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe,org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe</value></property>
<property><name>hive.limit.optimize.limit.file</name><value>10</value></property>
<property><name>mapred.healthChecker.script.timeout</name><value>600000</value></property>
<property><name>user.name</name><value>casa</value></property>
<property><name>hive.stats.dbconnectionstring</name><value>jdbc:derby:;databaseName=TempStatsStore;create=true</value></property>
<property><name>hive.metastore.fs.handler.class</name><value>org.apache.hadoop.hive.metastore.HiveMetaStoreFsImpl</value></property>
<property><name>mapreduce.job.submithostaddress</name><value>10.11.1.192</value></property>
<property><name>hive.compute.query.using.stats</name><value>false</value></property>
<property><name>hive.exec.job.debug.timeout</name><value>30000</value></property>
<property><name>dfs.secondary.http.address</name><value>0.0.0.0:50090</value></property>
<property><name>hive.enforce.bucketmapjoin</name><value>false</value></property>
<property><name>hive.unlock.numretries</name><value>10</value></property>
<property><name>fs.ramfs.impl</name><value>org.apache.hadoop.fs.InMemoryFileSystem</value></property>
<property><name>hive.enforce.sortmergebucketmapjoin</name><value>false</value></property>
<property><name>hive.mapjoin.bucket.cache.size</name><value>100</value></property>
<property><name>io.sort.mb</name><value>100</value></property>
<property><name>hive.session.silent</name><value>false</value></property>
<property><name>dfs.replication.interval</name><value>3</value></property>
<property><name>hive.script.operator.truncate.env</name><value>false</value></property>
<property><name>dfs.name.dir</name><value>/home/imdb/apacheHadoop/data1,/home/imdb/apacheHadoop/data2</value></property>
<property><name>hive.smbjoin.cache.rows</name><value>10000</value></property>
<property><name>fs.s3n.impl</name><value>org.apache.hadoop.fs.s3native.NativeS3FileSystem</value></property>
<property><name>hive.metastore.event.clean.freq</name><value>0</value></property>
<property><name>hive.conf.validation</name><value>true</value></property>
<property><name>mapred.output.value.class</name><value>org.apache.hadoop.io.Text</value></property>
<property><name>dfs.blockreport.initialDelay</name><value>0</value></property>
<property><name>hive.autogen.columnalias.prefix.label</name><value>_c</value></property>
<property><name>hive.optimize.multigroupby.common.distincts</name><value>true</value></property>
<property><name>hive.server2.thrift.http.min.worker.threads</name><value>5</value></property>
<property><name>hive.auto.convert.sortmerge.join.to.mapjoin</name><value>false</value></property>
<property><name>hive.stats.key.prefix.max.length</name><value>200</value></property>
<property><name>mapred.tasktracker.indexcache.mb</name><value>10</value></property>
<property><name>hive.map.aggr.hash.force.flush.memory.threshold</name><value>0.9</value></property>
<property><name>keep.failed.task.files</name><value>false</value></property>
<property><name>hive.support.quoted.identifiers</name><value>column</value></property>
<property><name>hive.lock.numretries</name><value>100</value></property>
<property><name>hive.metastore.cache.pinobjtypes</name><value>Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order</value></property>
<property><name>hive.optimize.sampling.orderby.number</name><value>1000</value></property>
<property><name>hive.cluster.delegation.token.store.zookeeper.acl</name><value>sasl:hive/host1@EXAMPLE.COM:cdrwa,sasl:hive/host2@EXAMPLE.COM:cdrwa</value></property>
<property><name>dfs.default.chunk.view.size</name><value>32768</value></property>
<property><name>mapreduce.job.acl-modify-job</name><value> </value></property>
<property><name>hive.skewjoin.mapjoin.map.tasks</name><value>10000</value></property>
<property><name>mapred.heartbeats.in.second</name><value>100</value></property>
<property><name>hive.metastore.failure.retries</name><value>3</value></property>
<property><name>dfs.permissions</name><value>false</value></property>
<property><name>hive.compactor.delta.num.threshold</name><value>10</value></property>
<property><name>mapreduce.job.submithost</name><value>90s192</value></property>
<property><name>hive.stats.fetch.partition.stats</name><value>true</value></property>
<property><name>fs.checkpoint.dir</name><value>${hadoop.tmp.dir}/dfs/namesecondary</value></property>
<property><name>hive.ppd.remove.duplicatefilters</name><value>true</value></property>
<property><name>hive.optimize.index.autoupdate</name><value>false</value></property>
<property><name>hive.scratch.dir.permission</name><value>700</value></property>
<property><name>ipc.client.kill.max</name><value>10</value></property>
<property><name>hive.explain.dependency.append.tasktype</name><value>false</value></property>
<property><name>hive.exec.scratchdir</name><value>/tmp/hive-${user.name}</value></property>
<property><name>mapreduce.tasktracker.outofband.heartbeat.damper</name><value>1000000</value></property>
<property><name>hadoop.security.uid.cache.secs</name><value>14400</value></property>
<property><name>mapred.tasktracker.dns.interface</name><value>default</value></property>
<property><name>mapred.child.java.opts</name><value>-Xmx2048m</value></property>
<property><name>stream.stderr.reporter.enabled</name><value>true</value></property>
<property><name>hive.fetch.task.conversion.threshold</name><value>-1</value></property>
<property><name>hadoop.logfile.size</name><value>10000000</value></property>
<property><name>hive.merge.size.per.task</name><value>256000000</value></property>
<property><name>hive.stats.jdbc.timeout</name><value>30</value></property>
<property><name>mapred.job.map.memory.mb</name><value>-1</value></property>
<property><name>io.sort.factor</name><value>10</value></property>
<property><name>hive.optimize.index.filter.compact.maxsize</name><value>-1</value></property>
<property><name>dfs.https.server.keystore.resource</name><value>ssl-server.xml</value></property>
<property><name>dfs.datanode.handler.count</name><value>3</value></property>
<property><name>hive.warehouse.subdir.inherit.perms</name><value>false</value></property>
<property><name>hive.hwi.war.file</name><value>lib/hive-hwi-@VERSION@.war</value></property>
<property><name>mapred.max.split.size</name><value>256000000</value></property>
<property><name>hive.metastore.thrift.framed.transport.enabled</name><value>false</value></property>
<property><name>dfs.https.need.client.auth</name><value>false</value></property>
<property><name>hive.compactor.delta.pct.threshold</name><value>0.1</value></property>
<property><name>hive.zookeeper.namespace</name><value>hive_zookeeper_namespace</value></property>
<property><name>mapreduce.workflow.id</name><value>hive_casa_20150309152424_cc80bb1e-b7f6-49b6-80c7-b0dde40761e1</value></property>
<property><name>dfs.namenode.delegation.key.update-interval</name><value>86400000</value></property>
<property><name>hive.exec.parallel</name><value>false</value></property>
<property><name>hive.optimize.index.groupby</name><value>false</value></property>
<property><name>mapreduce.job.acl-view-job</name><value> </value></property>
<property><name>hive.server2.table.type.mapping</name><value>CLASSIC</value></property>
<property><name>hive.optimize.listbucketing</name><value>false</value></property>
<property><name>hive.optimize.union.remove</name><value>false</value></property>
<property><name>dfs.namenode.decommission.interval</name><value>30</value></property>
<property><name>hive.default.rcfile.serde</name><value>org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe</value></property>
<property><name>hive.optimize.sort.dynamic.partition</name><value>true</value></property>
<property><name>hive.cli.prompt</name><value>hive</value></property>
<property><name>hive.optimize.reducededuplication.min.reducer</name><value>4</value></property>
<property><name>dfs.client.block.write.retries</name><value>3</value></property>
<property><name>fs.checkpoint.edits.dir</name><value>${fs.checkpoint.dir}</value></property>
<property><name>hive.tez.log.level</name><value>INFO</value></property>
<property><name>hive.compactor.worker.threads</name><value>0</value></property>
<property><name>hive.server2.transport.mode</name><value>binary</value></property>
<property><name>hive.jobname.length</name><value>50</value></property>
<property><name>dfs.support.append</name><value>true</value></property>
<property><name>io.skip.checksum.errors</name><value>false</value></property>
<property><name>hive.server2.thrift.max.worker.threads</name><value>500</value></property>
<property><name>hive.fileformat.check</name><value>true</value></property>
<property><name>mapred.job.tracker.persist.jobstatus.hours</name><value>0</value></property>
<property><name>hive.auto.convert.sortmerge.join.bigtable.selection.policy</name><value>org.apache.hadoop.hive.ql.optimizer.AvgPartitionSizeBasedBigTableSelectorForAutoSMJ</value></property>
<property><name>hive.mapper.cannot.span.multiple.partitions</name><value>false</value></property>
<property><name>datanucleus.rdbms.useLegacyNativeValueStrategy</name><value>true</value></property>
<property><name>ipc.client.idlethreshold</name><value>4000</value></property>
<property><name>mapred.job.reuse.jvm.num.tasks</name><value>1</value></property>
<property><name>mapred.create.symlink</name><value>yes</value></property>
<property><name>hive.txn.valid.txns</name><value>9223372036854775807:</value></property>
<property><name>hive.stats.list.num.entries</name><value>10</value></property>
<property><name>topology.node.switch.mapping.impl</name><value>org.apache.hadoop.net.ScriptBasedMapping</value></property>
<property><name>hive.exec.dynamic.partition</name><value>true</value></property>
<property><name>mapred.cluster.reduce.memory.mb</name><value>-1</value></property>
<property><name>hive.lock.sleep.between.retries</name><value>60</value></property>
<property><name>hive.stats.jdbcdriver</name><value>org.apache.derby.jdbc.EmbeddedDriver</value></property>
<property><name>mapred.task.cache.levels</name><value>2</value></property>
<property><name>hive.stats.map.parallelism</name><value>1</value></property>
<property><name>fs.kfs.impl</name><value>org.apache.hadoop.fs.kfs.KosmosFileSystem</value></property>
<property><name>hive.stats.collect.tablekeys</name><value>false</value></property>
<property><name>ipc.server.listen.queue.size</name><value>128</value></property>
<property><name>hive.exec.script.allow.partial.consumption</name><value>false</value></property>
<property><name>hive.stats.atomic</name><value>false</value></property>
<property><name>dfs.access.time.precision</name><value>3600000</value></property>
<property><name>hadoop.security.group.mapping</name><value>org.apache.hadoop.security.ShellBasedUnixGroupsMapping</value></property>
<property><name>hive.optimize.index.filter</name><value>false</value></property>
<property><name>hive.merge.current.job.concatenate.list.bucketing</name><value>true</value></property>
<property><name>mapred.queue.names</name><value>default</value></property>
<property><name>hive.metastore.try.direct.sql</name><value>true</value></property>
<property><name>hive.cli.print.current.db</name><value>false</value></property>
<property><name>mapreduce.reduce.input.limit</name><value>-1</value></property>
<property><name>javax.jdo.option.ConnectionPassword</name><value>HIVE</value></property>
<property><name>hive.hwi.listen.port</name><value>9999</value></property>
<property><name>io.compression.codecs</name><value>org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.BZip2Codec,org.apache.hadoop.io.compress.SnappyCodec</value></property>
<property><name>fs.checkpoint.size</name><value>67108864</value></property>
<property><name>hive.exec.max.dynamic.partitions</name><value>1000</value></property>
<property><name>hive.vectorized.groupby.flush.percent</name><value>0.1</value></property>
<property><name>hive.auto.convert.join.use.nonstaged</name><value>false</value></property>
<property><name>hive.script.recordwriter</name><value>org.apache.hadoop.hive.ql.exec.TextRecordWriter</value></property>
<property><name>hive.stats.retries.wait</name><value>3000</value></property>
<property><name>mapred.jobtracker.blacklist.fault-bucket-width</name><value>15</value></property>
<property><name>hive.hmshandler.retry.attempts</name><value>1</value></property>
<property><name>mapred.job.queue.name</name><value>default</value></property>
<property><name>hive.txn.manager</name><value>org.apache.hadoop.hive.ql.lockmgr.DummyTxnManager</value></property>
<property><name>hive.script.operator.id.env.var</name><value>HIVE_SCRIPT_OPERATOR_ID</value></property>
<property><name>dfs.balance.bandwidthPerSec</name><value>20971520</value></property>
<property><name>hive.metastore.archive.intermediate.extracted</name><value>_INTERMEDIATE_EXTRACTED</value></property>
<property><name>hive.tez.input.format</name><value>org.apache.hadoop.hive.ql.io.HiveInputFormat</value></property>
<property><name>mapred.user.jobconf.limit</name><value>5242880</value></property>
<property><name>mapred.skip.reduce.auto.incr.proc.count</name><value>true</value></property>
<property><name>mapred.job.tracker.persist.jobstatus.active</name><value>false</value></property>
<property><name>datanucleus.fixedDatastore</name><value>false</value></property>
<property><name>hive.exec.orc.zerocopy</name><value>false</value></property>
<property><name>mapred.combine.recordsBeforeProgress</name><value>10000</value></property>
<property><name>hive.optimize.index.filter.compact.minsize</name><value>5368709120</value></property>
<property><name>hive.map.aggr.hash.min.reduction</name><value>0.5</value></property>
<property><name>mapred.output.committer.class</name><value>org.apache.hadoop.hive.shims.HadoopShimsSecure$NullOutputCommitter</value></property>
<property><name>hive.display.partition.cols.separately</name><value>true</value></property>
<property><name>hive.cache.expr.evaluation</name><value>true</value></property>
<property><name>hive.mapjoin.localtask.max.memory.usage</name><value>0.90</value></property>
<property><name>hive.error.on.empty.partition</name><value>false</value></property>
<property><name>hive.exec.script.trust</name><value>false</value></property>
<property><name>dfs.block.access.key.update.interval</name><value>600</value></property>
<property><name>hive.stats.tmp.loc</name><value>hdfs://10.11.1.192:9000/tmp/hive-casa/hive_2015-03-09_15-24-45_148_8355964799932482103-1/-ext-10002</value></property>
<property><name>mapred.map.output.compression.codec</name><value>org.apache.hadoop.io.compress.DefaultCodec</value></property>
<property><name>hadoop.tmp.dir</name><value>/home/imdb/apacheHadoop/tmp</value></property>
<property><name>hive.exec.concatenate.check.index</name><value>true</value></property>
<property><name>hive.outerjoin.supports.filters</name><value>true</value></property>
<property><name>mapred.queue.default.state</name><value>RUNNING</value></property>
<property><name>hive.ddl.output.format</name><value>text</value></property>
<property><name>hive.exec.mode.local.auto.input.files.max</name><value>4</value></property>
<property><name>hive.session.history.enabled</name><value>false</value></property>
<property><name>hive.groupby.orderby.position.alias</name><value>false</value></property>
<property><name>mapred.task.tracker.http.address</name><value>0.0.0.0:50060</value></property>
<property><name>hive.stats.gather.num.threads</name><value>10</value></property>
<property><name>hive.server2.long.polling.timeout</name><value>5000L</value></property>
<property><name>hive.server2.thrift.http.path</name><value>cliservice</value></property>
<property><name>hive.mapjoin.optimized.keys</name><value>true</value></property>
<property><name>dfs.datanode.dns.interface</name><value>default</value></property>
<property><name>mapred.task.profile.reduces</name><value>0-2</value></property>
<property><name>hive.query.result.fileformat</name><value>TextFile</value></property>
<property><name>mapred.inmem.merge.threshold</name><value>1000</value></property>
<property><name>hive.archive.enabled</name><value>false</value></property>
<property><name>datanucleus.cache.level2</name><value>false</value></property>
<property><name>hive.exec.tasklog.debug.timeout</name><value>20000</value></property>
<property><name>hive.server2.thrift.http.max.worker.threads</name><value>500</value></property>
<property><name>hive.metastore.try.direct.sql.ddl</name><value>true</value></property>
<property><name>dfs.datanode.http.address</name><value>0.0.0.0:50075</value></property>
<property><name>hive.auto.convert.join.noconditionaltask</name><value>true</value></property>
<property><name>hive.server2.async.exec.wait.queue.size</name><value>100</value></property>
<property><name>mapred.jar</name><value>hdfs://10.11.1.192:9000/home/imdb/apacheHadoop/tmp/mapred/staging/casa/.staging/job_201502131503_0011/job.jar</value></property>
<property><name>hive.cli.pretty.output.num.cols</name><value>-1</value></property>
<property><name>dfs.safemode.extension</name><value>30000</value></property>
<property><name>hive.compactor.initiator.on</name><value>false</value></property>
<property><name>fs.checkpoint.period</name><value>3600</value></property>
<property><name>dfs.datanode.address</name><value>0.0.0.0:50010</value></property>
<property><name>dfs.block.access.token.enable</name><value>false</value></property>
<property><name>hive.enforce.bucketing</name><value>false</value></property>
<property><name>fs.hdfs.impl.disable.cache</name><value>false</value></property>
<property><name>hive.mapjoin.lazy.hashtable</name><value>true</value></property>
<property><name>hive.security.metastore.authorization.manager</name><value>org.apache.hadoop.hive.ql.security.authorization.DefaultHiveMetastoreAuthorizationProvider</value></property>
<property><name>hive.ignore.mapjoin.hint</name><value>true</value></property>
<property><name>dfs.blockreport.intervalMsec</name><value>3600000</value></property>
<property><name>hive.metastore.ds.retry.attempts</name><value>1</value></property>
<property><name>hive.zookeeper.clean.extra.nodes</name><value>false</value></property>
<property><name>hive.exec.parallel.thread.number</name><value>8</value></property>
<property><name>hive.index.compact.query.max.size</name><value>10737418240</value></property>
<property><name>io.bytes.per.checksum</name><value>512</value></property>
<property><name>dfs.data.dir</name><value>/home/imdb/apacheHadoop/data</value></property>
<property><name>dfs.https.enable</name><value>false</value></property>
<property><name>mapred.local.dir</name><value>/home/imdb/apacheHadoop/var</value></property>
<property><name>hive.compactor.check.interval</name><value>300</value></property>
<property><name>map.sort.class</name><value>org.apache.hadoop.util.QuickSort</value></property>
<property><name>hive.auto.convert.join.noconditionaltask.size</name><value>10000000</value></property>
<property><name>job.end.retry.interval</name><value>30000</value></property>
<property><name>hive.merge.tezfiles</name><value>false</value></property>
<property><name>io.seqfile.compress.blocksize</name><value>1000000</value></property>
<property><name>mapred.input.dir</name><value>hdfs://10.11.1.192:9000/tmp/hive-casa/hive_2015-03-09_15-24-45_148_8355964799932482103-1/-mr-10003</value></property>
<property><name>mapred.output.compression.type</name><value>RECORD</value></property>
<property><name>hive.input.format.sorted</name><value>false</value></property>
<property><name>hive.stats.map.num.entries</name><value>10</value></property>
<property><name>mapreduce.jobtracker.staging.root.dir</name><value>${hadoop.tmp.dir}/mapred/staging</value></property>
<property><name>hive.hashtable.initialCapacity</name><value>100000</value></property>
<property><name>hive.metastore.server.tcp.keepalive</name><value>true</value></property>
<property><name>hive.metastore.kerberos.principal</name><value>hive-metastore/_HOST@EXAMPLE.COM</value></property>
<property><name>mapreduce.job.dir</name><value>hdfs://10.11.1.192:9000/home/imdb/apacheHadoop/tmp/mapred/staging/casa/.staging/job_201502131503_0011</value></property>
<property><name>hive.metastore.archive.intermediate.archived</name><value>_INTERMEDIATE_ARCHIVED</value></property>
<property><name>hive.rework.mapredwork</name><value>false</value></property>
<property><name>io.sort.spill.percent</name><value>0.80</value></property>
<property><name>hive.metastore.expression.proxy</name><value>org.apache.hadoop.hive.ql.optimizer.ppr.PartitionExpressionForMetastore</value></property>
<property><name>mapred.cache.files.timestamps</name><value>1425886048525,1425886048547</value></property>
<property><name>fs.hsftp.impl</name><value>org.apache.hadoop.hdfs.HsftpFileSystem</value></property>
<property><name>hive.map.aggr.hash.percentmemory</name><value>0.5</value></property>
<property><name>hive.compactor.abortedtxn.threshold</name><value>1000</value></property>
<property><name>hive.index.compact.file.ignore.hdfs</name><value>false</value></property>
<property><name>hive.server2.async.exec.keepalive.time</name><value>10</value></property>
<property><name>hive.auto.convert.sortmerge.join</name><value>false</value></property>
<property><name>hive.tez.container.size</name><value>-1</value></property>
<property><name>hive.entity.separator</name><value>@</value></property>
<property><name>hive.compactor.worker.timeout</name><value>86400</value></property>
<property><name>hive.hbase.wal.enabled</name><value>true</value></property>
<property><name>hive.optimize.skewjoin</name><value>false</value></property>
<property><name>dfs.permissions.supergroup</name><value>supergroup</value></property>
<property><name>hive.exec.orc.default.buffer.size</name><value>262144</value></property>
<property><name>datanucleus.validateColumns</name><value>false</value></property>
<property><name>hive.current.database</name><value>default</value></property>
<property><name>hive.vectorized.execution.enabled</name><value>false</value></property>
<property><name>hive.exim.uri.scheme.whitelist</name><value>hdfs,pfile</value></property>
<property><name>tasktracker.http.threads</name><value>40</value></property>
<property><name>hive.metadata.move.exported.metadata.to.trash</name><value>true</value></property>
<property><name>hive.mapjoin.followby.map.aggr.hash.percentmemory</name><value>0.3</value></property>
<property><name>hadoop.bin.path</name><value>/home/imdb/tools/hadoop-1.0.3/libexec/../bin/hadoop</value></property>
<property><name>hive.limit.pushdown.memory.usage</name><value>0.3f</value></property>
<property><name>hive.optimize.groupby</name><value>true</value></property>
<property><name>hive.new.job.grouping.set.cardinality</name><value>30</value></property>
<property><name>hive.mapred.partitioner</name><value>org.apache.hadoop.hive.ql.io.DefaultHivePartitioner</value></property>
<property><name>mapred.compress.map.output</name><value>false</value></property>
<property><name>mapred.reducer.class</name><value>org.apache.hadoop.hive.ql.exec.mr.ExecReducer</value></property>
<property><name>hive.optimize.ppd</name><value>true</value></property>
<property><name>hive.server2.thrift.port</name><value>10000</value></property>
<property><name>hadoop.logfile.count</name><value>10</value></property>
<property><name>mapred.job.reduce.input.buffer.percent</name><value>0.0</value></property>
<property><name>fs.trash.interval</name><value>0</value></property>
<property><name>mapred.tasktracker.tasks.sleeptime-before-sigkill</name><value>5000</value></property>
<property><name>hive.exec.compress.output</name><value>false</value></property>
<property><name>dfs.datanode.du.reserved</name><value>0</value></property>
<property><name>hive.cluster.delegation.token.store.zookeeper.connectString</name><value>localhost:2181</value></property>
<property><name>hive.script.recordreader</name><value>org.apache.hadoop.hive.ql.exec.TextRecordReader</value></property>
<property><name>mapreduce.workflow.name</name><value>select count(*) from left16 join right16 on left16.a=right16.a</value></property>
<property><name>hive.heartbeat.interval</name><value>1000</value></property>
<property><name>mapred.tasktracker.dns.nameserver</name><value>default</value></property>
<property><name>hive.skewjoin.key</name><value>100000</value></property>
<property><name>hive.exec.counters.pull.interval</name><value>1000</value></property>
<property><name>hive.exec.submitviachild</name><value>false</value></property>
<property><name>hadoop.security.authorization</name><value>false</value></property>
<property><name>dfs.datanode.https.address</name><value>0.0.0.0:50475</value></property>
<property><name>hive.metastore.warehouse.dir</name><value>/user/hive/warehouse</value></property>
<property><name>mapred.max.tracker.blacklists</name><value>4</value></property>
<property><name>topology.script.number.args</name><value>100</value></property>
<property><name>local.cache.size</name><value>10737418240</value></property>
<property><name>hive.security.authenticator.manager</name><value>org.apache.hadoop.hive.ql.security.HadoopDefaultAuthenticator</value></property>
<property><name>hive.typecheck.on.insert</name><value>true</value></property>
<property><name>fs.s3.impl</name><value>org.apache.hadoop.fs.s3.S3FileSystem</value></property>
<property><name>hive.plan.serialization.format</name><value>kryo</value></property>
<property><name>javax.jdo.option.ConnectionURL</name><value>jdbc:derby:;databaseName=metastore_db;create=true</value></property>
<property><name>hive.querylog.plan.progress.interval</name><value>60000</value></property>
<property><name>hive.exec.local.scratchdir</name><value>/tmp/${user.name}</value></property>
<property><name>hive.cluster.delegation.token.store.zookeeper.znode</name><value>/hive/cluster/delegation</value></property>
<property><name>mapred.job.shuffle.input.buffer.percent</name><value>0.70</value></property>
<property><name>mapreduce.reduce.shuffle.connect.timeout</name><value>180000</value></property>
<property><name>dfs.datanode.failed.volumes.tolerated</name><value>0</value></property>
<property><name>hive.counters.group.name</name><value>HIVE</value></property>
<property><name>hive.multigroupby.singlereducer</name><value>false</value></property>
<property><name>dfs.datanode.data.dir.perm</name><value>755</value></property>
<property><name>hive.fetch.output.serde</name><value>org.apache.hadoop.hive.serde2.DelimitedJSONSerDe</value></property>
<property><name>hive.binary.record.max.length</name><value>1000</value></property>
<property><name>hive.server2.thrift.bind.host</name><value>localhost</value></property>
<property><name>javax.jdo.option.ConnectionDriverName</name><value>org.apache.derby.jdbc.EmbeddedDriver</value></property>
<property><name>hive.hwi.listen.host</name><value>0.0.0.0</value></property>
<property><name>hive.hadoop.supports.splittable.combineinputformat</name><value>false</value></property>
<property><name>io.serializations</name><value>org.apache.hadoop.io.serializer.WritableSerialization</value></property>
<property><name>mapred.merge.recordsBeforeProgress</name><value>10000</value></property>
<property><name>hive.stats.ndv.error</name><value>20.0</value></property>
<property><name>fs.s3.block.size</name><value>67108864</value></property>
<property><name>mapred.mapoutput.value.class</name><value>org.apache.hadoop.io.BytesWritable</value></property>
<property><name>hive.execution.engine</name><value>mr</value></property>
<property><name>mapred.jobtracker.restart.recover</name><value>false</value></property>
<property><name>hive.test.mode.prefix</name><value>test_</value></property>
<property><name>hive.downloaded.resources.dir</name><value>/tmp/${hive.session.id}_resources</value></property>
<property><name>hive.mapjoin.smalltable.filesize</name><value>25000000</value></property>
<property><name>mapred.map.tasks.speculative.execution</name><value>true</value></property>
<property><name>hive.compat</name><value>0.12</value></property>
<property><name>dfs.namenode.delegation.token.max-lifetime</name><value>604800000</value></property>
<property><name>hive.exec.rcfile.use.explicit.header</name><value>true</value></property>
<property><name>dfs.heartbeat.interval</name><value>3</value></property>
<property><name>io.map.index.skip</name><value>0</value></property>
<property><name>dfs.namenode.handler.count</name><value>10</value></property>
<property><name>hive.groupby.mapaggr.checkinterval</name><value>100000</value></property>
<property><name>mapred.mapper.class</name><value>org.apache.hadoop.hive.ql.exec.mr.ExecMapper</value></property>
<property><name>hive.exec.drop.ignorenonexistent</name><value>true</value></property>
<property><name>mapred.cache.files.filesizes</name><value>1277,2157</value></property>
<property><name>hive.server2.max.start.attempts</name><value>30</value></property>
<property><name>hive.exec.orc.default.compress</name><value>ZLIB</value></property>
<property><name>mapred.job.tracker.jobhistory.lru.cache.size</name><value>5</value></property>
<property><name>fs.har.impl.disable.cache</name><value>true</value></property>
<property><name>mapreduce.workflow.adjacency.Stage-6</name><value>Stage-1</value></property>
<property><name>hive.hmshandler.force.reload.conf</name><value>false</value></property>
<property><name>datanucleus.transactionIsolation</name><value>read-committed</value></property>
<property><name>mapreduce.workflow.adjacency.Stage-1</name><value>Stage-2</value></property>
<property><name>hive.prewarm.numcontainers</name><value>10</value></property>
<property><name>hadoop.util.hash.type</name><value>murmur</value></property>
<property><name>hive.optimize.correlation</name><value>false</value></property>
<property><name>hive.server.read.socket.timeout</name><value>10</value></property>
<property><name>hive.map.groupby.sorted.testmode</name><value>false</value></property>
<property><name>mapred.cluster.max.map.memory.mb</name><value>-1</value></property>
<property><name>mapred.task.tracker.report.address</name><value>127.0.0.1:0</value></property>
<property><name>hive.exec.compress.intermediate</name><value>false</value></property>
<property><name>mapred.input.dir.recursive</name><value>false</value></property>
<property><name>mapred.skip.map.max.skip.records</name><value>0</value></property>
<property><name>io.seqfile.sorter.recordlimit</name><value>1000000</value></property>
<property><name>hive.exec.script.maxerrsize</name><value>100000</value></property>
<property><name>hive.exec.rowoffset</name><value>false</value></property>
<property><name>mapred.task.profile.maps</name><value>0-2</value></property>
<property><name>hive.server2.thrift.http.port</name><value>10001</value></property>
<property><name>hive.lock.mapred.only.operation</name><value>false</value></property>
<property><name>mapred.cluster.max.reduce.memory.mb</name><value>-1</value></property>
<property><name>dfs.web.ugi</name><value>webuser,webgroup</value></property>
<property><name>hive.start.cleanup.scratchdir</name><value>false</value></property>
</configuration>