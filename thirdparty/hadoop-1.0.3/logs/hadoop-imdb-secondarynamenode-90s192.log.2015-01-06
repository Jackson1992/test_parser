2015-01-06 00:03:48,013 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 00:03:48,022 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 00:03:48,024 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 00:03:48,024 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 00:03:48,024 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 19.63 MB
2015-01-06 00:03:48,025 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 00:03:48,025 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 00:03:48,027 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 00:03:48,027 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 00:03:48,027 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 00:03:48,028 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 00:03:48,028 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 00:03:48,028 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 00:03:48,029 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 00:03:48,029 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 00:03:48,029 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 00:03:48,029 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 00:03:48,030 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 00:08:48,033 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 00:08:48,041 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 00:08:48,043 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 00:08:48,043 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 00:08:48,043 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 19.63 MB
2015-01-06 00:08:48,043 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 00:08:48,043 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 00:08:48,045 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 00:08:48,046 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 00:08:48,046 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 00:08:48,046 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 00:08:48,046 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 00:08:48,046 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 00:08:48,047 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 00:08:48,047 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 00:08:48,048 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 00:08:48,048 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 00:08:48,048 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 00:13:48,052 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 00:13:48,061 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 00:13:48,063 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 00:13:48,063 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 00:13:48,063 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 19.63 MB
2015-01-06 00:13:48,063 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 00:13:48,063 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 00:13:48,065 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 00:13:48,065 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 00:13:48,065 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 00:13:48,066 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 00:13:48,066 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 00:13:48,066 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 00:13:48,067 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 00:13:48,067 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 00:13:48,067 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 00:13:48,068 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 00:13:48,068 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 00:18:48,072 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 00:18:48,079 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 00:18:48,081 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 00:18:48,081 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 00:18:48,081 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 19.63 MB
2015-01-06 00:18:48,081 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 00:18:48,081 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 00:18:48,133 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 00:18:48,133 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 00:18:48,133 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 00:18:48,134 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 00:18:48,134 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 00:18:48,135 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 00:18:48,137 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 00:18:48,138 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 00:18:48,139 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 00:18:48,139 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 00:18:48,139 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 00:23:48,144 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 00:23:48,152 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 00:23:48,154 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 00:23:48,154 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 00:23:48,154 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.87 MB
2015-01-06 00:23:48,154 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 00:23:48,154 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 00:23:48,157 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 00:23:48,157 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 00:23:48,157 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 00:23:48,157 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 00:23:48,157 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 00:23:48,158 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 00:23:48,158 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 00:23:48,159 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 00:23:48,159 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 00:23:48,159 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 00:23:48,159 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 00:28:48,163 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 00:28:48,169 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 00:28:48,171 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 00:28:48,171 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 00:28:48,171 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.87 MB
2015-01-06 00:28:48,171 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 00:28:48,171 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 00:28:48,173 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 00:28:48,174 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 00:28:48,174 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 00:28:48,174 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 00:28:48,174 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 00:28:48,174 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 00:28:48,175 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 00:28:48,175 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 00:28:48,175 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 00:28:48,176 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 00:28:48,176 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 00:33:48,179 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 00:33:48,187 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 00:33:48,189 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 00:33:48,189 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 00:33:48,189 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.87 MB
2015-01-06 00:33:48,189 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 00:33:48,189 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 00:33:48,191 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 00:33:48,192 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 00:33:48,192 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 00:33:48,192 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 00:33:48,192 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 00:33:48,192 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 00:33:48,193 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 00:33:48,193 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 00:33:48,194 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 00:33:48,194 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 00:33:48,194 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 00:38:48,198 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 00:38:48,206 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 00:38:48,208 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 00:38:48,208 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 00:38:48,208 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.87 MB
2015-01-06 00:38:48,208 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 00:38:48,208 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 00:38:48,210 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 00:38:48,211 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 00:38:48,211 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 00:38:48,211 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 00:38:48,211 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 00:38:48,211 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 00:38:48,212 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 00:38:48,212 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 00:38:48,212 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 00:38:48,213 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 00:38:48,213 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 00:43:48,217 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 00:43:48,225 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 00:43:48,227 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 00:43:48,227 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 00:43:48,227 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.87 MB
2015-01-06 00:43:48,227 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 00:43:48,227 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 00:43:48,230 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 00:43:48,230 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 00:43:48,230 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 00:43:48,230 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 00:43:48,230 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 00:43:48,231 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 00:43:48,231 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 00:43:48,232 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 00:43:48,232 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 00:43:48,232 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 00:43:48,233 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 00:48:48,236 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 00:48:48,244 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 00:48:48,246 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 00:48:48,246 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 00:48:48,247 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.87 MB
2015-01-06 00:48:48,247 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 00:48:48,247 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 00:48:48,249 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 00:48:48,249 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 00:48:48,249 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 00:48:48,249 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 00:48:48,250 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 00:48:48,250 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 00:48:48,251 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 00:48:48,251 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 00:48:48,251 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 00:48:48,251 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 00:48:48,251 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 00:53:48,255 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 00:53:48,263 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 00:53:48,265 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 00:53:48,265 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 00:53:48,265 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.87 MB
2015-01-06 00:53:48,265 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 00:53:48,265 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 00:53:48,268 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 00:53:48,268 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 00:53:48,268 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 00:53:48,268 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 00:53:48,268 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 00:53:48,268 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 00:53:48,269 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 00:53:48,269 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 00:53:48,270 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 00:53:48,270 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 00:53:48,270 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 00:58:48,274 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 00:58:48,282 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 00:58:48,284 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 00:58:48,284 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 00:58:48,284 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.87 MB
2015-01-06 00:58:48,284 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 00:58:48,284 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 00:58:48,286 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 00:58:48,287 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 00:58:48,287 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 00:58:48,287 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 00:58:48,287 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 00:58:48,287 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 00:58:48,288 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 00:58:48,288 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 00:58:48,289 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 00:58:48,289 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 00:58:48,289 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 01:03:48,293 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 01:03:48,301 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 01:03:48,303 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 01:03:48,303 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 01:03:48,303 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.87 MB
2015-01-06 01:03:48,303 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 01:03:48,303 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 01:03:48,306 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 01:03:48,306 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 01:03:48,306 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 01:03:48,306 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 01:03:48,306 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 01:03:48,306 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 01:03:48,307 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 01:03:48,307 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 01:03:48,308 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 01:03:48,308 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 01:03:48,308 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 01:08:48,312 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 01:08:48,319 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 01:08:48,321 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 01:08:48,321 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 01:08:48,321 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.87 MB
2015-01-06 01:08:48,321 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 01:08:48,321 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 01:08:48,324 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 01:08:48,324 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 01:08:48,324 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 01:08:48,324 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 01:08:48,325 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 01:08:48,325 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 01:08:48,326 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 01:08:48,326 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 01:08:48,326 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 01:08:48,326 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 01:08:48,327 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 01:13:48,330 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 01:13:48,338 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 01:13:48,340 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 01:13:48,340 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 01:13:48,340 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.87 MB
2015-01-06 01:13:48,340 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 01:13:48,340 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 01:13:48,342 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 01:13:48,342 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 01:13:48,342 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 01:13:48,343 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 01:13:48,343 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 01:13:48,343 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 01:13:48,344 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 01:13:48,344 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 01:13:48,344 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 01:13:48,345 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 01:13:48,345 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 01:18:48,349 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 01:18:48,357 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 01:18:48,359 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 01:18:48,359 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 01:18:48,359 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.87 MB
2015-01-06 01:18:48,359 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 01:18:48,359 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 01:18:48,362 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 01:18:48,362 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 01:18:48,362 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 01:18:48,362 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 01:18:48,362 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 01:18:48,362 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 01:18:48,363 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 01:18:48,364 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 01:18:48,364 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 01:18:48,364 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 01:18:48,364 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 01:23:48,368 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 01:23:48,385 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 01:23:48,387 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 01:23:48,387 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 01:23:48,387 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.87 MB
2015-01-06 01:23:48,388 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 01:23:48,388 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 01:23:48,390 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 01:23:48,390 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 01:23:48,390 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 01:23:48,391 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 01:23:48,391 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 01:23:48,391 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 01:23:48,392 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 01:23:48,392 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 01:23:48,392 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 01:23:48,392 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 01:23:48,393 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 01:28:48,396 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 01:28:48,404 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 01:28:48,406 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 01:28:48,406 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 01:28:48,406 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.87 MB
2015-01-06 01:28:48,406 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 01:28:48,406 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 01:28:48,408 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 01:28:48,409 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 01:28:48,409 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 01:28:48,409 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 01:28:48,409 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 01:28:48,409 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 01:28:48,410 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 01:28:48,410 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 01:28:48,411 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 01:28:48,411 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 01:28:48,411 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 01:33:48,415 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 01:33:48,423 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 01:33:48,425 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 01:33:48,425 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 01:33:48,425 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.87 MB
2015-01-06 01:33:48,425 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 01:33:48,425 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 01:33:48,428 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 01:33:48,428 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 01:33:48,428 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 01:33:48,428 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 01:33:48,428 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 01:33:48,429 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 01:33:48,429 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 01:33:48,430 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 01:33:48,430 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 01:33:48,430 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 01:33:48,430 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 01:38:48,435 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 01:38:48,443 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 01:38:48,445 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 01:38:48,445 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 01:38:48,445 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.87 MB
2015-01-06 01:38:48,445 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 01:38:48,445 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 01:38:48,448 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 01:38:48,448 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 01:38:48,448 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 01:38:48,448 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 01:38:48,448 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 01:38:48,448 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 01:38:48,449 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 01:38:48,450 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 01:38:48,450 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 01:38:48,450 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 01:38:48,450 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 01:43:48,454 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 01:43:48,461 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 01:43:48,463 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 01:43:48,463 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 01:43:48,463 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.87 MB
2015-01-06 01:43:48,463 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 01:43:48,463 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 01:43:48,466 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 01:43:48,466 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 01:43:48,466 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 01:43:48,466 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 01:43:48,466 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 01:43:48,467 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 01:43:48,467 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 01:43:48,468 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 01:43:48,468 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 01:43:48,468 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 01:43:48,468 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 01:48:48,472 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 01:48:48,480 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 01:48:48,482 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 01:48:48,482 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 01:48:48,482 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.87 MB
2015-01-06 01:48:48,482 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 01:48:48,482 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 01:48:48,485 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 01:48:48,485 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 01:48:48,485 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 01:48:48,486 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 01:48:48,486 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 01:48:48,486 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 01:48:48,487 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 01:48:48,487 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 01:48:48,487 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 01:48:48,487 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 01:48:48,488 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 01:53:48,491 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 01:53:48,498 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 01:53:48,500 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 01:53:48,500 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 01:53:48,500 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.87 MB
2015-01-06 01:53:48,501 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 01:53:48,501 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 01:53:48,503 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 01:53:48,503 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 01:53:48,503 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 01:53:48,504 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 01:53:48,504 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 01:53:48,504 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 01:53:48,505 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 01:53:48,505 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 01:53:48,505 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 01:53:48,505 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 01:53:48,506 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 01:58:48,509 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 01:58:48,568 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 01:58:48,571 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 01:58:48,571 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 01:58:48,571 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.75 MB
2015-01-06 01:58:48,571 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 01:58:48,571 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 01:58:48,574 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 01:58:48,574 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 01:58:48,574 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 01:58:48,574 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 01:58:48,574 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 01:58:48,574 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 01:58:48,575 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 01:58:48,575 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 01:58:48,576 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 01:58:48,576 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 01:58:48,576 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 02:03:48,580 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 02:03:48,588 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 02:03:48,590 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 02:03:48,590 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 02:03:48,590 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.75 MB
2015-01-06 02:03:48,590 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 02:03:48,590 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 02:03:48,593 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 02:03:48,593 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 02:03:48,593 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 02:03:48,593 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 02:03:48,593 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 02:03:48,594 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 02:03:48,594 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 02:03:48,595 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 02:03:48,595 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 02:03:48,595 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 02:03:48,595 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 02:08:48,599 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 02:08:48,606 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 02:08:48,608 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 02:08:48,608 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 02:08:48,608 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.75 MB
2015-01-06 02:08:48,608 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 02:08:48,608 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 02:08:48,610 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 02:08:48,611 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 02:08:48,611 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 02:08:48,611 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 02:08:48,611 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 02:08:48,611 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 02:08:48,612 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 02:08:48,612 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 02:08:48,613 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 02:08:48,613 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 02:08:48,613 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 02:13:48,616 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 02:13:48,624 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 02:13:48,626 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 02:13:48,626 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 02:13:48,626 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.75 MB
2015-01-06 02:13:48,626 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 02:13:48,626 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 02:13:48,629 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 02:13:48,629 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 02:13:48,629 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 02:13:48,629 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 02:13:48,629 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 02:13:48,629 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 02:13:48,630 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 02:13:48,630 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 02:13:48,631 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 02:13:48,631 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 02:13:48,631 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 02:18:48,635 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 02:18:48,642 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 02:18:48,644 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 02:18:48,644 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 02:18:48,644 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.75 MB
2015-01-06 02:18:48,644 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 02:18:48,645 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 02:18:48,647 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 02:18:48,647 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 02:18:48,647 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 02:18:48,647 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 02:18:48,648 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 02:18:48,648 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 02:18:48,649 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 02:18:48,649 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 02:18:48,649 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 02:18:48,649 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 02:18:48,650 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 02:23:48,653 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 02:23:48,661 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 02:23:48,663 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 02:23:48,663 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 02:23:48,663 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.75 MB
2015-01-06 02:23:48,663 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 02:23:48,663 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 02:23:48,666 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 02:23:48,666 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 02:23:48,666 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 02:23:48,666 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 02:23:48,666 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 02:23:48,667 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 02:23:48,667 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 02:23:48,668 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 02:23:48,668 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 02:23:48,668 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 02:23:48,669 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 02:28:48,672 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 02:28:48,680 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 02:28:48,681 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 02:28:48,682 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 02:28:48,682 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.75 MB
2015-01-06 02:28:48,682 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 02:28:48,682 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 02:28:48,684 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 02:28:48,684 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 02:28:48,684 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 02:28:48,685 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 02:28:48,685 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 02:28:48,685 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 02:28:48,686 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 02:28:48,686 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 02:28:48,686 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 02:28:48,686 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 02:28:48,687 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 02:33:48,690 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 02:33:48,698 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 02:33:48,700 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 02:33:48,700 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 02:33:48,700 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.75 MB
2015-01-06 02:33:48,700 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 02:33:48,700 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 02:33:48,702 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 02:33:48,703 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 02:33:48,703 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 02:33:48,703 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 02:33:48,703 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 02:33:48,703 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 02:33:48,704 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 02:33:48,704 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 02:33:48,705 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 02:33:48,705 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 02:33:48,705 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 02:38:48,709 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 02:38:48,716 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 02:38:48,718 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 02:38:48,718 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 02:38:48,718 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.75 MB
2015-01-06 02:38:48,718 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 02:38:48,718 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 02:38:48,720 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 02:38:48,720 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 02:38:48,721 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 02:38:48,721 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 02:38:48,721 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 02:38:48,721 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 02:38:48,722 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 02:38:48,722 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 02:38:48,722 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 02:38:48,723 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 02:38:48,723 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 02:43:48,726 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 02:43:48,734 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 02:43:48,736 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 02:43:48,736 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 02:43:48,736 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.75 MB
2015-01-06 02:43:48,736 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 02:43:48,736 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 02:43:48,739 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 02:43:48,739 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 02:43:48,739 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 02:43:48,739 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 02:43:48,739 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 02:43:48,740 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 02:43:48,740 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 02:43:48,741 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 02:43:48,741 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 02:43:48,741 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 02:43:48,741 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 02:48:48,745 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 02:48:48,752 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 02:48:48,754 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 02:48:48,754 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 02:48:48,754 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.75 MB
2015-01-06 02:48:48,754 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 02:48:48,754 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 02:48:48,757 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 02:48:48,757 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 02:48:48,757 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 02:48:48,757 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 02:48:48,757 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 02:48:48,758 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 02:48:48,758 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 02:48:48,759 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 02:48:48,759 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 02:48:48,759 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 02:48:48,759 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 02:53:48,763 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 02:53:48,770 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 02:53:48,772 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 02:53:48,773 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 02:53:48,773 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.75 MB
2015-01-06 02:53:48,773 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 02:53:48,773 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 02:53:48,775 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 02:53:48,775 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 02:53:48,775 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 02:53:48,776 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 02:53:48,776 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 02:53:48,776 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 02:53:48,777 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 02:53:48,777 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 02:53:48,777 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 02:53:48,777 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 02:53:48,778 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 02:58:48,781 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 02:58:48,789 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 02:58:48,791 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 02:58:48,791 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 02:58:48,791 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.75 MB
2015-01-06 02:58:48,791 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 02:58:48,791 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 02:58:48,794 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 02:58:48,794 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 02:58:48,794 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 02:58:48,794 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 02:58:48,794 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 02:58:48,794 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 02:58:48,795 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 02:58:48,795 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 02:58:48,796 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 02:58:48,796 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 02:58:48,796 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 03:03:48,800 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 03:03:48,807 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 03:03:48,809 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 03:03:48,809 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 03:03:48,809 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.75 MB
2015-01-06 03:03:48,809 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 03:03:48,809 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 03:03:48,811 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 03:03:48,812 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 03:03:48,812 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 03:03:48,812 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 03:03:48,812 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 03:03:48,812 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 03:03:48,813 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 03:03:48,813 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 03:03:48,814 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 03:03:48,814 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 03:03:48,814 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 03:08:48,818 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 03:08:48,825 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 03:08:48,827 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 03:08:48,827 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 03:08:48,827 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.75 MB
2015-01-06 03:08:48,827 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 03:08:48,827 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 03:08:48,830 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 03:08:48,830 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 03:08:48,830 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 03:08:48,830 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 03:08:48,830 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 03:08:48,830 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 03:08:48,831 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 03:08:48,831 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 03:08:48,832 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 03:08:48,832 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 03:08:48,832 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 03:13:48,836 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 03:13:48,843 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 03:13:48,845 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 03:13:48,845 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 03:13:48,846 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.75 MB
2015-01-06 03:13:48,846 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 03:13:48,846 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 03:13:48,848 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 03:13:48,848 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 03:13:48,848 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 03:13:48,849 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 03:13:48,849 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 03:13:48,849 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 03:13:48,850 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 03:13:48,850 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 03:13:48,850 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 03:13:48,851 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 03:13:48,851 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 03:18:48,854 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 03:18:48,862 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 03:18:48,863 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 03:18:48,864 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 03:18:48,864 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.75 MB
2015-01-06 03:18:48,864 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 03:18:48,864 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 03:18:48,866 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 03:18:48,866 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 03:18:48,866 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 03:18:48,867 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 03:18:48,867 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 03:18:48,867 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 03:18:48,868 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 03:18:48,868 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 03:18:48,868 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 03:18:48,869 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 03:18:48,869 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 03:23:48,874 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 03:23:48,890 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 03:23:48,892 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 03:23:48,892 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 03:23:48,892 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.75 MB
2015-01-06 03:23:48,892 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 03:23:48,892 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 03:23:48,895 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 03:23:48,895 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 03:23:48,895 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 03:23:48,895 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 03:23:48,895 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 03:23:48,896 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 03:23:48,897 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 03:23:48,897 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 03:23:48,897 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 03:23:48,897 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 03:23:48,897 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 03:28:48,900 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 03:28:48,908 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 03:28:48,910 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 03:28:48,910 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 03:28:48,910 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.75 MB
2015-01-06 03:28:48,910 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 03:28:48,910 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 03:28:48,913 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 03:28:48,913 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 03:28:48,913 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 03:28:48,913 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 03:28:48,913 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 03:28:48,914 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 03:28:48,914 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 03:28:48,915 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 03:28:48,915 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 03:28:48,915 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 03:28:48,915 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 03:33:48,919 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 03:33:48,926 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 03:33:48,928 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 03:33:48,928 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 03:33:48,928 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.75 MB
2015-01-06 03:33:48,928 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 03:33:48,928 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 03:33:48,976 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 03:33:48,977 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 03:33:48,977 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 03:33:48,977 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 03:33:48,977 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 03:33:48,977 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 03:33:48,978 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 03:33:48,978 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 03:33:48,978 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 03:33:48,978 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 03:33:48,978 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 03:38:48,982 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 03:38:48,989 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 03:38:48,991 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 03:38:48,991 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 03:38:48,991 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.61 MB
2015-01-06 03:38:48,991 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 03:38:48,991 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 03:38:48,994 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 03:38:48,994 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 03:38:48,994 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 03:38:48,994 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 03:38:48,994 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 03:38:48,995 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 03:38:48,995 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 03:38:48,996 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 03:38:48,996 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 03:38:48,996 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 03:38:48,996 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 03:43:49,000 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 03:43:49,007 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 03:43:49,009 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 03:43:49,009 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 03:43:49,009 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.61 MB
2015-01-06 03:43:49,009 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 03:43:49,009 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 03:43:49,012 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 03:43:49,012 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 03:43:49,012 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 03:43:49,012 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 03:43:49,012 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 03:43:49,013 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 03:43:49,013 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 03:43:49,014 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 03:43:49,014 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 03:43:49,014 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 03:43:49,014 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 03:48:49,018 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 03:48:49,025 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 03:48:49,027 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 03:48:49,028 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 03:48:49,028 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.61 MB
2015-01-06 03:48:49,028 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 03:48:49,028 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 03:48:49,030 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 03:48:49,030 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 03:48:49,030 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 03:48:49,031 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 03:48:49,031 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 03:48:49,031 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 03:48:49,032 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 03:48:49,032 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 03:48:49,032 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 03:48:49,032 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 03:48:49,033 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 03:53:49,036 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 03:53:49,045 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 03:53:49,047 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 03:53:49,047 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 03:53:49,047 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.61 MB
2015-01-06 03:53:49,047 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 03:53:49,047 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 03:53:49,049 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 03:53:49,050 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 03:53:49,050 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 03:53:49,050 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 03:53:49,050 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 03:53:49,050 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 03:53:49,051 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 03:53:49,051 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 03:53:49,052 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 03:53:49,052 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 03:53:49,052 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 03:58:49,055 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 03:58:49,063 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 03:58:49,065 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 03:58:49,065 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 03:58:49,065 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.61 MB
2015-01-06 03:58:49,065 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 03:58:49,065 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 03:58:49,067 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 03:58:49,068 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 03:58:49,068 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 03:58:49,068 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 03:58:49,068 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 03:58:49,068 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 03:58:49,069 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 03:58:49,069 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 03:58:49,070 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 03:58:49,070 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 03:58:49,070 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 04:03:49,074 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 04:03:49,091 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 04:03:49,093 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 04:03:49,093 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 04:03:49,093 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.61 MB
2015-01-06 04:03:49,093 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 04:03:49,093 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 04:03:49,095 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 04:03:49,096 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 04:03:49,096 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 04:03:49,096 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 04:03:49,096 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 04:03:49,096 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 04:03:49,097 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 04:03:49,097 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 04:03:49,098 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 04:03:49,098 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 04:03:49,098 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 04:08:49,102 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 04:08:49,109 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 04:08:49,111 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 04:08:49,111 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 04:08:49,111 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.61 MB
2015-01-06 04:08:49,111 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 04:08:49,111 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 04:08:49,114 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 04:08:49,114 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 04:08:49,114 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 04:08:49,114 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 04:08:49,114 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 04:08:49,115 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 04:08:49,115 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 04:08:49,116 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 04:08:49,116 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 04:08:49,116 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 04:08:49,116 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 04:13:49,120 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 04:13:49,127 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 04:13:49,129 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 04:13:49,130 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 04:13:49,130 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.61 MB
2015-01-06 04:13:49,130 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 04:13:49,130 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 04:13:49,132 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 04:13:49,132 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 04:13:49,132 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 04:13:49,133 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 04:13:49,133 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 04:13:49,133 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 04:13:49,134 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 04:13:49,134 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 04:13:49,134 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 04:13:49,135 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 04:13:49,135 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 04:18:49,139 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 04:18:49,146 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 04:18:49,148 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 04:18:49,149 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 04:18:49,149 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.61 MB
2015-01-06 04:18:49,149 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 04:18:49,149 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 04:18:49,151 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 04:18:49,151 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 04:18:49,151 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 04:18:49,152 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 04:18:49,152 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 04:18:49,152 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 04:18:49,153 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 04:18:49,153 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 04:18:49,153 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 04:18:49,153 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 04:18:49,154 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 04:23:49,157 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 04:23:49,168 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 04:23:49,170 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 04:23:49,170 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 04:23:49,170 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.61 MB
2015-01-06 04:23:49,170 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 04:23:49,170 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 04:23:49,172 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 04:23:49,173 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 04:23:49,173 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 04:23:49,173 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 04:23:49,173 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 04:23:49,173 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 04:23:49,174 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 04:23:49,174 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 04:23:49,175 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 04:23:49,175 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 04:23:49,175 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 04:28:49,179 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 04:28:49,186 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 04:28:49,188 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 04:28:49,188 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 04:28:49,188 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.61 MB
2015-01-06 04:28:49,188 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 04:28:49,188 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 04:28:49,191 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 04:28:49,191 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 04:28:49,191 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 04:28:49,191 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 04:28:49,191 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 04:28:49,191 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 04:28:49,192 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 04:28:49,192 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 04:28:49,193 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 04:28:49,193 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 04:28:49,193 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 04:33:49,197 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 04:33:49,204 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 04:33:49,206 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 04:33:49,206 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 04:33:49,206 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.61 MB
2015-01-06 04:33:49,206 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 04:33:49,206 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 04:33:49,209 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 04:33:49,209 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 04:33:49,209 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 04:33:49,209 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 04:33:49,209 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 04:33:49,210 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 04:33:49,210 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 04:33:49,211 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 04:33:49,211 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 04:33:49,211 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 04:33:49,211 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 04:38:49,215 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 04:38:49,223 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 04:38:49,224 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 04:38:49,225 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 04:38:49,225 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.61 MB
2015-01-06 04:38:49,225 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 04:38:49,225 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 04:38:49,227 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 04:38:49,227 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 04:38:49,227 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 04:38:49,228 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 04:38:49,228 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 04:38:49,228 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 04:38:49,229 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 04:38:49,229 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 04:38:49,229 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 04:38:49,230 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 04:38:49,230 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 04:43:49,233 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 04:43:49,241 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 04:43:49,243 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 04:43:49,243 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 04:43:49,243 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.61 MB
2015-01-06 04:43:49,243 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 04:43:49,243 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 04:43:49,246 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 04:43:49,246 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 04:43:49,246 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 04:43:49,246 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 04:43:49,246 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 04:43:49,246 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 04:43:49,247 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 04:43:49,247 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 04:43:49,248 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 04:43:49,248 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 04:43:49,248 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 04:48:49,251 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 04:48:49,259 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 04:48:49,261 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 04:48:49,261 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 04:48:49,261 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.61 MB
2015-01-06 04:48:49,261 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 04:48:49,261 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 04:48:49,263 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 04:48:49,264 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 04:48:49,264 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 04:48:49,264 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 04:48:49,264 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 04:48:49,264 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 04:48:49,265 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 04:48:49,265 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 04:48:49,266 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 04:48:49,266 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 04:48:49,266 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 04:53:49,270 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 04:53:49,278 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 04:53:49,280 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 04:53:49,280 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 04:53:49,280 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.61 MB
2015-01-06 04:53:49,280 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 04:53:49,280 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 04:53:49,282 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 04:53:49,282 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 04:53:49,282 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 04:53:49,283 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 04:53:49,283 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 04:53:49,283 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 04:53:49,284 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 04:53:49,284 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 04:53:49,284 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 04:53:49,285 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 04:53:49,285 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 04:58:49,288 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 04:58:49,296 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 04:58:49,298 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 04:58:49,298 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 04:58:49,298 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.61 MB
2015-01-06 04:58:49,299 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 04:58:49,299 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 04:58:49,301 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 04:58:49,301 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 04:58:49,301 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 04:58:49,302 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 04:58:49,302 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 04:58:49,302 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 04:58:49,303 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 04:58:49,303 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 04:58:49,303 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 04:58:49,303 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 04:58:49,304 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 05:03:49,307 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 05:03:49,314 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 05:03:49,316 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 05:03:49,317 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 05:03:49,317 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.61 MB
2015-01-06 05:03:49,317 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 05:03:49,317 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 05:03:49,319 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 05:03:49,319 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 05:03:49,319 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 05:03:49,320 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 05:03:49,320 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 05:03:49,320 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 05:03:49,321 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 05:03:49,321 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 05:03:49,321 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 05:03:49,322 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 05:03:49,322 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 05:08:49,325 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 05:08:49,333 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 05:08:49,335 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 05:08:49,335 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 05:08:49,335 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.61 MB
2015-01-06 05:08:49,335 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 05:08:49,335 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 05:08:49,386 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 05:08:49,386 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 05:08:49,386 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 05:08:49,386 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 05:08:49,386 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 05:08:49,386 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 05:08:49,387 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 05:08:49,387 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 05:08:49,387 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 05:08:49,387 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 05:08:49,387 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 05:13:49,391 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 05:13:49,398 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 05:13:49,400 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 05:13:49,400 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 05:13:49,400 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.49 MB
2015-01-06 05:13:49,400 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 05:13:49,401 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 05:13:49,403 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 05:13:49,403 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 05:13:49,403 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 05:13:49,403 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 05:13:49,404 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 05:13:49,404 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 05:13:49,405 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 05:13:49,405 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 05:13:49,405 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 05:13:49,405 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 05:13:49,406 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 05:18:49,409 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 05:18:49,416 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 05:18:49,418 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 05:18:49,418 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 05:18:49,419 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.49 MB
2015-01-06 05:18:49,419 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 05:18:49,419 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 05:18:49,421 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 05:18:49,421 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 05:18:49,421 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 05:18:49,422 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 05:18:49,422 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 05:18:49,422 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 05:18:49,423 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 05:18:49,423 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 05:18:49,423 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 05:18:49,423 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 05:18:49,424 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 05:23:49,427 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 05:23:49,435 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 05:23:49,437 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 05:23:49,437 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 05:23:49,437 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.49 MB
2015-01-06 05:23:49,437 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 05:23:49,437 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 05:23:49,440 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 05:23:49,440 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 05:23:49,440 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 05:23:49,440 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 05:23:49,440 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 05:23:49,441 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 05:23:49,441 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 05:23:49,442 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 05:23:49,442 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 05:23:49,442 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 05:23:49,442 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 05:28:49,446 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 05:28:49,453 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 05:28:49,455 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 05:28:49,455 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 05:28:49,455 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.49 MB
2015-01-06 05:28:49,455 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 05:28:49,455 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 05:28:49,458 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 05:28:49,458 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 05:28:49,458 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 05:28:49,458 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 05:28:49,458 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 05:28:49,459 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 05:28:49,459 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 05:28:49,460 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 05:28:49,460 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 05:28:49,460 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 05:28:49,460 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 05:33:49,464 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 05:33:49,471 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 05:33:49,473 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 05:33:49,473 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 05:33:49,473 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.49 MB
2015-01-06 05:33:49,473 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 05:33:49,474 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 05:33:49,476 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 05:33:49,476 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 05:33:49,476 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 05:33:49,476 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 05:33:49,476 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 05:33:49,477 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 05:33:49,477 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 05:33:49,478 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 05:33:49,478 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 05:33:49,478 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 05:33:49,478 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 05:38:49,482 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 05:38:49,489 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 05:38:49,491 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 05:38:49,491 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 05:38:49,491 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.49 MB
2015-01-06 05:38:49,491 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 05:38:49,491 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 05:38:49,494 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 05:38:49,494 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 05:38:49,494 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 05:38:49,494 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 05:38:49,494 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 05:38:49,495 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 05:38:49,495 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 05:38:49,496 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 05:38:49,496 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 05:38:49,496 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 05:38:49,496 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 05:43:49,500 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 05:43:49,508 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 05:43:49,510 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 05:43:49,510 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 05:43:49,510 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.49 MB
2015-01-06 05:43:49,510 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 05:43:49,511 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 05:43:49,513 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 05:43:49,513 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 05:43:49,513 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 05:43:49,513 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 05:43:49,514 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 05:43:49,514 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 05:43:49,515 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 05:43:49,515 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 05:43:49,515 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 05:43:49,515 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 05:43:49,516 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 05:48:49,519 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 05:48:49,526 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 05:48:49,528 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 05:48:49,529 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 05:48:49,529 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.49 MB
2015-01-06 05:48:49,529 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 05:48:49,529 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 05:48:49,531 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 05:48:49,531 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 05:48:49,531 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 05:48:49,532 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 05:48:49,532 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 05:48:49,532 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 05:48:49,533 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 05:48:49,533 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 05:48:49,533 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 05:48:49,534 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 05:48:49,534 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 05:53:49,537 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 05:53:49,545 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 05:53:49,546 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 05:53:49,547 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 05:53:49,547 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.49 MB
2015-01-06 05:53:49,547 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 05:53:49,547 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 05:53:49,549 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 05:53:49,549 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 05:53:49,549 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 05:53:49,550 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 05:53:49,550 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 05:53:49,550 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 05:53:49,551 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 05:53:49,551 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 05:53:49,551 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 05:53:49,552 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 05:53:49,552 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 05:58:49,555 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 05:58:49,562 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 05:58:49,564 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 05:58:49,564 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 05:58:49,564 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.49 MB
2015-01-06 05:58:49,565 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 05:58:49,565 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 05:58:49,567 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 05:58:49,567 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 05:58:49,567 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 05:58:49,567 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 05:58:49,568 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 05:58:49,568 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 05:58:49,569 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 05:58:49,569 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 05:58:49,569 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 05:58:49,569 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 05:58:49,570 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 06:03:49,573 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 06:03:49,580 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 06:03:49,582 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 06:03:49,582 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 06:03:49,582 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.49 MB
2015-01-06 06:03:49,583 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 06:03:49,583 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 06:03:49,585 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 06:03:49,585 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 06:03:49,585 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 06:03:49,585 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 06:03:49,586 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 06:03:49,586 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 06:03:49,587 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 06:03:49,587 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 06:03:49,587 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 06:03:49,587 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 06:03:49,588 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 06:08:49,591 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 06:08:49,598 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 06:08:49,600 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 06:08:49,600 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 06:08:49,600 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.49 MB
2015-01-06 06:08:49,600 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 06:08:49,600 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 06:08:49,603 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 06:08:49,603 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 06:08:49,603 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 06:08:49,603 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 06:08:49,603 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 06:08:49,603 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 06:08:49,604 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 06:08:49,604 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 06:08:49,605 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 06:08:49,605 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 06:08:49,605 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 06:13:49,608 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 06:13:49,616 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 06:13:49,618 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 06:13:49,618 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 06:13:49,618 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.49 MB
2015-01-06 06:13:49,618 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 06:13:49,618 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 06:13:49,621 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 06:13:49,621 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 06:13:49,621 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 06:13:49,621 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 06:13:49,621 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 06:13:49,621 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 06:13:49,622 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 06:13:49,622 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 06:13:49,623 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 06:13:49,623 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 06:13:49,623 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 06:18:49,626 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 06:18:49,634 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 06:18:49,635 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 06:18:49,635 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 06:18:49,636 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.49 MB
2015-01-06 06:18:49,636 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 06:18:49,636 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 06:18:49,638 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 06:18:49,638 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 06:18:49,638 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 06:18:49,639 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 06:18:49,639 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 06:18:49,639 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 06:18:49,640 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 06:18:49,640 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 06:18:49,640 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 06:18:49,640 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 06:18:49,641 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 06:23:49,644 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 06:23:49,652 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 06:23:49,653 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 06:23:49,654 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 06:23:49,654 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.49 MB
2015-01-06 06:23:49,654 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 06:23:49,654 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 06:23:49,656 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 06:23:49,656 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 06:23:49,657 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 06:23:49,657 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 06:23:49,657 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 06:23:49,657 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 06:23:49,658 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 06:23:49,658 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 06:23:49,658 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 06:23:49,659 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 06:23:49,659 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 06:28:49,662 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 06:28:49,669 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 06:28:49,671 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 06:28:49,671 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 06:28:49,671 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.49 MB
2015-01-06 06:28:49,672 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 06:28:49,672 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 06:28:49,674 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 06:28:49,674 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 06:28:49,674 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 06:28:49,674 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 06:28:49,675 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 06:28:49,675 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 06:28:49,676 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 06:28:49,676 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 06:28:49,676 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 06:28:49,676 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 06:28:49,677 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 06:33:49,680 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 06:33:49,687 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 06:33:49,689 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 06:33:49,689 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 06:33:49,689 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.49 MB
2015-01-06 06:33:49,690 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 06:33:49,690 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 06:33:49,692 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 06:33:49,692 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 06:33:49,692 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 06:33:49,693 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 06:33:49,693 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 06:33:49,693 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 06:33:49,694 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 06:33:49,694 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 06:33:49,694 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 06:33:49,694 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 06:33:49,695 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 06:38:49,698 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 06:38:49,706 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 06:38:49,708 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 06:38:49,708 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 06:38:49,708 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.49 MB
2015-01-06 06:38:49,708 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 06:38:49,708 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 06:38:49,711 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 06:38:49,711 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 06:38:49,711 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 06:38:49,711 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 06:38:49,711 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 06:38:49,711 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 06:38:49,712 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 06:38:49,712 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 06:38:49,713 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 06:38:49,713 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 06:38:49,713 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 06:43:49,716 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 06:43:49,724 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 06:43:49,725 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 06:43:49,725 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 06:43:49,726 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.4 MB
2015-01-06 06:43:49,726 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 06:43:49,726 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 06:43:49,728 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 06:43:49,728 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 06:43:49,728 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 06:43:49,729 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 06:43:49,729 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 06:43:49,729 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 06:43:49,730 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 06:43:49,730 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 06:43:49,730 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 06:43:49,731 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 06:43:49,731 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 06:48:49,734 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 06:48:49,742 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 06:48:49,744 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 06:48:49,744 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 06:48:49,744 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.4 MB
2015-01-06 06:48:49,744 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 06:48:49,744 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 06:48:49,746 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 06:48:49,747 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 06:48:49,747 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 06:48:49,747 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 06:48:49,747 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 06:48:49,747 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 06:48:49,748 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 06:48:49,748 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 06:48:49,748 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 06:48:49,749 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 06:48:49,749 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 06:53:49,752 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 06:53:49,759 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 06:53:49,761 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 06:53:49,761 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 06:53:49,762 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.4 MB
2015-01-06 06:53:49,762 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 06:53:49,762 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 06:53:49,764 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 06:53:49,764 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 06:53:49,764 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 06:53:49,764 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 06:53:49,765 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 06:53:49,765 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 06:53:49,766 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 06:53:49,766 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 06:53:49,766 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 06:53:49,766 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 06:53:49,767 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 06:58:49,770 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 06:58:49,777 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 06:58:49,779 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 06:58:49,779 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 06:58:49,779 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.4 MB
2015-01-06 06:58:49,779 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 06:58:49,779 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 06:58:49,782 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 06:58:49,782 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 06:58:49,782 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 06:58:49,782 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 06:58:49,782 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 06:58:49,782 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 06:58:49,783 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 06:58:49,783 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 06:58:49,784 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 06:58:49,784 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 06:58:49,784 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 07:03:49,788 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 07:03:49,795 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 07:03:49,797 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 07:03:49,797 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 07:03:49,797 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.4 MB
2015-01-06 07:03:49,797 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 07:03:49,797 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 07:03:49,800 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 07:03:49,800 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 07:03:49,800 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 07:03:49,800 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 07:03:49,800 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 07:03:49,800 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 07:03:49,801 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 07:03:49,801 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 07:03:49,802 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 07:03:49,802 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 07:03:49,802 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 07:08:49,805 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 07:08:49,813 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 07:08:49,815 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 07:08:49,815 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 07:08:49,815 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.4 MB
2015-01-06 07:08:49,815 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 07:08:49,815 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 07:08:49,818 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 07:08:49,818 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 07:08:49,818 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 07:08:49,818 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 07:08:49,818 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 07:08:49,818 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 07:08:49,819 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 07:08:49,819 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 07:08:49,820 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 07:08:49,820 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 07:08:49,820 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 07:13:49,823 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 07:13:49,831 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 07:13:49,833 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 07:13:49,833 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 07:13:49,833 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.4 MB
2015-01-06 07:13:49,833 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 07:13:49,833 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 07:13:49,836 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 07:13:49,836 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 07:13:49,836 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 07:13:49,836 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 07:13:49,836 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 07:13:49,836 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 07:13:49,837 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 07:13:49,837 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 07:13:49,838 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 07:13:49,838 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 07:13:49,838 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 07:18:49,842 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 07:18:49,849 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 07:18:49,851 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 07:18:49,851 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 07:18:49,851 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.4 MB
2015-01-06 07:18:49,851 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 07:18:49,851 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 07:18:49,854 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 07:18:49,854 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 07:18:49,854 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 07:18:49,854 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 07:18:49,854 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 07:18:49,854 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 07:18:49,855 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 07:18:49,855 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 07:18:49,856 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 07:18:49,856 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 07:18:49,856 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 07:23:49,860 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 07:23:49,868 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 07:23:49,870 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 07:23:49,870 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 07:23:49,870 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.4 MB
2015-01-06 07:23:49,870 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 07:23:49,870 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 07:23:49,873 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 07:23:49,873 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 07:23:49,873 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 07:23:49,873 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 07:23:49,873 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 07:23:49,873 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 07:23:49,874 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 07:23:49,874 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 07:23:49,875 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 07:23:49,875 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 07:23:49,875 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 07:28:49,879 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 07:28:49,886 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 07:28:49,888 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 07:28:49,888 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 07:28:49,888 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.4 MB
2015-01-06 07:28:49,888 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 07:28:49,888 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 07:28:49,891 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 07:28:49,891 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 07:28:49,891 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 07:28:49,891 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 07:28:49,891 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 07:28:49,892 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 07:28:49,892 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 07:28:49,893 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 07:28:49,893 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 07:28:49,893 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 07:28:49,893 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 07:33:49,897 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 07:33:49,904 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 07:33:49,906 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 07:33:49,906 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 07:33:49,906 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.4 MB
2015-01-06 07:33:49,906 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 07:33:49,906 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 07:33:49,909 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 07:33:49,909 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 07:33:49,909 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 07:33:49,909 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 07:33:49,909 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 07:33:49,909 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 07:33:49,910 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 07:33:49,911 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 07:33:49,911 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 07:33:49,911 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 07:33:49,911 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 07:38:49,915 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 07:38:49,922 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 07:38:49,925 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 07:38:49,925 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 07:38:49,925 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.4 MB
2015-01-06 07:38:49,925 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 07:38:49,925 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 07:38:49,927 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 07:38:49,928 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 07:38:49,928 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 07:38:49,928 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 07:38:49,928 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 07:38:49,928 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 07:38:49,929 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 07:38:49,929 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 07:38:49,930 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 07:38:49,930 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 07:38:49,930 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 07:43:49,934 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 07:43:49,941 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 07:43:49,943 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 07:43:49,943 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 07:43:49,944 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.4 MB
2015-01-06 07:43:49,944 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 07:43:49,944 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 07:43:49,946 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 07:43:49,946 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 07:43:49,946 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 07:43:49,947 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 07:43:49,947 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 07:43:49,947 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 07:43:49,948 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 07:43:49,948 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 07:43:49,948 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 07:43:49,948 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 07:43:49,949 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 07:48:49,952 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 07:48:49,959 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 07:48:49,961 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 07:48:49,961 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 07:48:49,961 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.4 MB
2015-01-06 07:48:49,961 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 07:48:49,961 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 07:48:49,963 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 07:48:49,964 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 07:48:49,964 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 07:48:49,964 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 07:48:49,964 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 07:48:49,964 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 07:48:49,965 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 07:48:49,965 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 07:48:49,966 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 07:48:49,966 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 07:48:49,966 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 07:53:49,970 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 07:53:49,977 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 07:53:49,979 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 07:53:49,979 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 07:53:49,979 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.4 MB
2015-01-06 07:53:49,979 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 07:53:49,979 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 07:53:49,982 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 07:53:49,982 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 07:53:49,982 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 07:53:49,982 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 07:53:49,982 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 07:53:49,982 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 07:53:49,983 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 07:53:49,983 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 07:53:49,984 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 07:53:49,984 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 07:53:49,984 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 07:58:49,988 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 07:58:50,005 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 07:58:50,007 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 07:58:50,007 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 07:58:50,007 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.4 MB
2015-01-06 07:58:50,008 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 07:58:50,008 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 07:58:50,010 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 07:58:50,010 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 07:58:50,010 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 07:58:50,011 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 07:58:50,011 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 07:58:50,011 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 07:58:50,012 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 07:58:50,012 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 07:58:50,012 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 07:58:50,012 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 07:58:50,013 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 08:03:50,016 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 08:03:50,024 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 08:03:50,025 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 08:03:50,026 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 08:03:50,026 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.4 MB
2015-01-06 08:03:50,026 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 08:03:50,026 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 08:03:50,028 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 08:03:50,028 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 08:03:50,028 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 08:03:50,029 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 08:03:50,029 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 08:03:50,029 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 08:03:50,030 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 08:03:50,030 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 08:03:50,030 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 08:03:50,030 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 08:03:50,031 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 08:08:50,034 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 08:08:50,042 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 08:08:50,044 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 08:08:50,044 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 08:08:50,044 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.4 MB
2015-01-06 08:08:50,044 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 08:08:50,044 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 08:08:50,047 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 08:08:50,047 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 08:08:50,047 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 08:08:50,047 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 08:08:50,047 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 08:08:50,047 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 08:08:50,048 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 08:08:50,048 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 08:08:50,049 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 08:08:50,049 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 08:08:50,049 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 08:13:50,053 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 08:13:50,060 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 08:13:50,062 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 08:13:50,062 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 08:13:50,062 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.4 MB
2015-01-06 08:13:50,062 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 08:13:50,062 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 08:13:50,111 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 08:13:50,111 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 08:13:50,111 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 08:13:50,112 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 08:13:50,112 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 08:13:50,112 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 08:13:50,112 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 08:13:50,113 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 08:13:50,113 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 08:13:50,113 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 08:13:50,113 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 08:18:50,117 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 08:18:50,124 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 08:18:50,126 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 08:18:50,126 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 08:18:50,126 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.28 MB
2015-01-06 08:18:50,127 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 08:18:50,127 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 08:18:50,129 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 08:18:50,129 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 08:18:50,129 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 08:18:50,130 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 08:18:50,130 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 08:18:50,130 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 08:18:50,131 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 08:18:50,131 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 08:18:50,131 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 08:18:50,131 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 08:18:50,132 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 08:23:50,135 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 08:23:50,143 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 08:23:50,145 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 08:23:50,145 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 08:23:50,145 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.28 MB
2015-01-06 08:23:50,145 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 08:23:50,145 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 08:23:50,147 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 08:23:50,147 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 08:23:50,147 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 08:23:50,148 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 08:23:50,148 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 08:23:50,148 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 08:23:50,149 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 08:23:50,149 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 08:23:50,149 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 08:23:50,150 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 08:23:50,150 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 08:28:50,153 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 08:28:50,161 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 08:28:50,163 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 08:28:50,163 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 08:28:50,163 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.28 MB
2015-01-06 08:28:50,163 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 08:28:50,163 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 08:28:50,165 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 08:28:50,166 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 08:28:50,166 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 08:28:50,166 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 08:28:50,166 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 08:28:50,166 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 08:28:50,167 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 08:28:50,167 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 08:28:50,167 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 08:28:50,168 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 08:28:50,168 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 08:33:50,171 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 08:33:50,179 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 08:33:50,181 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 08:33:50,181 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 08:33:50,181 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.28 MB
2015-01-06 08:33:50,181 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 08:33:50,181 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 08:33:50,183 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 08:33:50,184 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 08:33:50,184 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 08:33:50,184 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 08:33:50,184 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 08:33:50,184 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 08:33:50,185 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 08:33:50,185 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 08:33:50,185 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 08:33:50,186 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 08:33:50,186 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 08:38:50,189 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 08:38:50,197 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 08:38:50,198 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 08:38:50,199 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 08:38:50,199 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.28 MB
2015-01-06 08:38:50,199 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 08:38:50,199 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 08:38:50,201 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 08:38:50,201 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 08:38:50,201 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 08:38:50,202 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 08:38:50,202 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 08:38:50,202 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 08:38:50,203 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 08:38:50,203 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 08:38:50,203 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 08:38:50,203 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 08:38:50,204 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 08:43:50,207 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 08:43:50,215 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 08:43:50,217 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 08:43:50,217 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 08:43:50,217 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.28 MB
2015-01-06 08:43:50,217 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 08:43:50,217 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 08:43:50,220 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 08:43:50,220 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 08:43:50,220 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 08:43:50,220 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 08:43:50,220 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 08:43:50,220 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 08:43:50,221 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 08:43:50,221 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 08:43:50,222 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 08:43:50,222 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 08:43:50,222 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 08:48:50,225 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 08:48:50,233 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 08:48:50,235 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 08:48:50,235 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 08:48:50,235 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.28 MB
2015-01-06 08:48:50,235 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 08:48:50,235 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 08:48:50,237 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 08:48:50,238 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 08:48:50,238 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 08:48:50,238 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 08:48:50,238 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 08:48:50,238 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 08:48:50,239 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 08:48:50,239 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 08:48:50,239 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 08:48:50,240 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 08:48:50,240 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 08:53:50,243 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 08:53:50,251 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 08:53:50,253 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 08:53:50,253 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 08:53:50,253 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.28 MB
2015-01-06 08:53:50,253 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 08:53:50,253 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 08:53:50,255 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 08:53:50,255 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 08:53:50,255 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 08:53:50,256 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 08:53:50,256 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 08:53:50,256 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 08:53:50,257 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 08:53:50,257 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 08:53:50,257 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 08:53:50,258 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 08:53:50,258 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 08:58:50,261 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 08:58:50,269 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 08:58:50,271 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 08:58:50,271 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 08:58:50,271 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.28 MB
2015-01-06 08:58:50,271 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 08:58:50,271 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 08:58:50,274 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 08:58:50,274 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 08:58:50,274 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 08:58:50,274 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 08:58:50,274 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 08:58:50,275 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 08:58:50,275 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 08:58:50,276 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 08:58:50,276 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 08:58:50,276 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 08:58:50,276 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 09:03:50,280 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 09:03:50,288 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 09:03:50,290 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 09:03:50,290 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 09:03:50,290 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.28 MB
2015-01-06 09:03:50,290 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 09:03:50,290 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 09:03:50,293 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 09:03:50,293 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 09:03:50,293 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 09:03:50,293 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 09:03:50,293 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 09:03:50,293 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 09:03:50,294 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 09:03:50,294 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 09:03:50,295 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 09:03:50,295 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 09:03:50,295 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 09:08:50,299 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 09:08:50,306 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 09:08:50,308 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 09:08:50,308 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 09:08:50,308 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.28 MB
2015-01-06 09:08:50,308 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 09:08:50,308 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 09:08:50,311 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 09:08:50,311 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 09:08:50,311 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 09:08:50,311 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 09:08:50,311 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 09:08:50,311 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 09:08:50,312 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 09:08:50,312 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 09:08:50,313 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 09:08:50,313 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 09:08:50,313 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 09:13:50,317 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 09:13:50,324 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 09:13:50,326 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 09:13:50,326 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 09:13:50,326 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.28 MB
2015-01-06 09:13:50,326 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 09:13:50,326 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 09:13:50,329 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 09:13:50,329 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 09:13:50,329 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 09:13:50,329 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 09:13:50,329 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 09:13:50,329 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 09:13:50,330 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 09:13:50,330 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 09:13:50,331 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 09:13:50,331 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 09:13:50,331 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 09:18:50,335 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 09:18:50,342 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 09:18:50,344 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 09:18:50,344 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 09:18:50,344 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.28 MB
2015-01-06 09:18:50,344 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 09:18:50,344 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 09:18:50,347 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 09:18:50,347 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 09:18:50,347 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 09:18:50,347 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 09:18:50,347 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 09:18:50,347 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 09:18:50,348 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 09:18:50,348 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 09:18:50,349 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 09:18:50,349 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 09:18:50,349 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 09:23:50,352 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 09:23:50,360 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 09:23:50,362 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 09:23:50,362 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 09:23:50,362 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.28 MB
2015-01-06 09:23:50,362 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 09:23:50,362 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 09:23:50,365 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 09:23:50,365 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 09:23:50,365 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 09:23:50,365 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 09:23:50,365 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 09:23:50,365 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 09:23:50,366 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 09:23:50,366 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 09:23:50,367 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 09:23:50,367 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 09:23:50,367 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 09:28:50,371 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 09:28:50,378 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 09:28:50,380 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 09:28:50,380 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 09:28:50,380 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.28 MB
2015-01-06 09:28:50,380 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 09:28:50,380 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 09:28:50,383 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 09:28:50,383 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 09:28:50,383 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 09:28:50,383 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 09:28:50,383 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 09:28:50,383 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 09:28:50,384 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 09:28:50,384 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 09:28:50,385 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 09:28:50,385 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 09:28:50,385 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 09:33:50,389 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 09:33:50,396 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 09:33:50,398 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 09:33:50,398 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 09:33:50,398 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.28 MB
2015-01-06 09:33:50,398 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 09:33:50,398 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 09:33:50,400 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 09:33:50,401 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 09:33:50,401 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 09:33:50,401 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 09:33:50,401 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 09:33:50,401 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 09:33:50,402 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 09:33:50,402 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 09:33:50,403 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 09:33:50,403 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 09:33:50,403 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 09:38:50,406 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 09:38:50,413 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 09:38:50,415 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 09:38:50,415 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 09:38:50,415 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.28 MB
2015-01-06 09:38:50,415 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 09:38:50,415 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 09:38:50,418 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 09:38:50,418 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 09:38:50,418 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 09:38:50,418 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 09:38:50,418 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 09:38:50,419 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 09:38:50,419 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 09:38:50,420 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 09:38:50,420 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 09:38:50,420 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 09:38:50,420 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 09:43:50,424 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 09:43:50,431 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 09:43:50,433 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 09:43:50,433 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 09:43:50,433 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.28 MB
2015-01-06 09:43:50,433 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 09:43:50,433 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 09:43:50,479 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 09:43:50,479 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 09:43:50,479 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 09:43:50,480 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 09:43:50,480 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 09:43:50,480 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 09:43:50,480 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 09:43:50,480 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 09:43:50,481 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 09:43:50,481 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 09:43:50,481 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 09:48:50,484 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 09:48:50,492 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 09:48:50,494 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 09:48:50,494 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 09:48:50,494 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 09:48:50,494 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 09:48:50,494 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 09:48:50,497 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 09:48:50,497 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 09:48:50,497 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 09:48:50,497 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 09:48:50,497 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 09:48:50,497 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 09:48:50,498 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 09:48:50,498 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 09:48:50,499 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 09:48:50,499 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 09:48:50,499 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 09:53:50,503 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 09:53:50,510 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 09:53:50,513 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 09:53:50,513 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 09:53:50,513 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 09:53:50,513 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 09:53:50,513 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 09:53:50,516 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 09:53:50,516 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 09:53:50,516 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 09:53:50,517 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 09:53:50,517 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 09:53:50,517 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 09:53:50,518 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 09:53:50,518 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 09:53:50,519 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 09:53:50,519 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 09:53:50,519 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 09:58:50,523 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 09:58:50,530 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 09:58:50,531 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 09:58:50,532 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 09:58:50,532 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 09:58:50,532 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 09:58:50,532 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 09:58:50,534 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 09:58:50,534 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 09:58:50,534 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 09:58:50,535 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 09:58:50,535 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 09:58:50,535 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 09:58:50,536 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 09:58:50,536 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 09:58:50,536 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 09:58:50,537 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 09:58:50,537 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 10:03:50,540 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 10:03:50,547 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 10:03:50,549 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 10:03:50,549 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 10:03:50,550 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 10:03:50,550 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 10:03:50,550 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 10:03:50,552 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 10:03:50,552 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 10:03:50,552 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 10:03:50,553 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 10:03:50,553 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 10:03:50,553 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 10:03:50,554 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 10:03:50,554 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 10:03:50,554 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 10:03:50,554 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 10:03:50,555 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 10:08:50,558 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 10:08:50,565 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 10:08:50,567 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 10:08:50,567 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 10:08:50,567 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 10:08:50,567 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 10:08:50,568 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 10:08:50,570 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 10:08:50,570 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 10:08:50,570 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 10:08:50,570 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 10:08:50,570 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 10:08:50,571 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 10:08:50,571 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 10:08:50,572 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 10:08:50,572 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 10:08:50,572 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 10:08:50,572 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 10:13:50,576 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 10:13:50,583 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 10:13:50,585 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 10:13:50,585 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 10:13:50,585 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 10:13:50,585 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 10:13:50,585 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 10:13:50,588 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 10:13:50,588 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 10:13:50,588 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 10:13:50,588 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 10:13:50,588 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 10:13:50,588 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 10:13:50,589 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 10:13:50,589 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 10:13:50,590 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 10:13:50,590 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 10:13:50,590 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 10:18:50,594 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 10:18:50,601 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 10:18:50,603 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 10:18:50,603 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 10:18:50,603 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 10:18:50,603 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 10:18:50,603 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 10:18:50,606 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 10:18:50,606 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 10:18:50,606 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 10:18:50,606 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 10:18:50,606 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 10:18:50,606 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 10:18:50,607 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 10:18:50,607 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 10:18:50,608 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 10:18:50,608 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 10:18:50,608 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 10:23:50,612 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 10:23:50,619 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 10:23:50,620 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 10:23:50,620 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 10:23:50,621 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 10:23:50,621 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 10:23:50,621 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 10:23:50,623 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 10:23:50,623 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 10:23:50,623 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 10:23:50,624 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 10:23:50,624 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 10:23:50,624 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 10:23:50,625 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 10:23:50,625 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 10:23:50,625 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 10:23:50,625 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 10:23:50,626 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 10:28:50,629 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 10:28:50,636 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 10:28:50,638 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 10:28:50,638 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 10:28:50,638 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 10:28:50,638 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 10:28:50,638 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 10:28:50,640 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 10:28:50,641 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 10:28:50,641 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 10:28:50,641 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 10:28:50,641 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 10:28:50,641 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 10:28:50,642 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 10:28:50,642 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 10:28:50,642 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 10:28:50,643 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 10:28:50,643 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 10:33:50,646 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 10:33:50,653 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 10:33:50,655 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 10:33:50,655 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 10:33:50,656 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 10:33:50,656 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 10:33:50,656 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 10:33:50,658 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 10:33:50,658 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 10:33:50,658 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 10:33:50,659 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 10:33:50,659 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 10:33:50,659 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 10:33:50,660 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 10:33:50,660 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 10:33:50,660 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 10:33:50,660 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 10:33:50,661 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 10:38:50,664 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 10:38:50,671 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 10:38:50,673 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 10:38:50,673 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 10:38:50,673 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 10:38:50,673 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 10:38:50,673 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 10:38:50,675 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 10:38:50,676 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 10:38:50,676 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 10:38:50,676 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 10:38:50,676 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 10:38:50,676 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 10:38:50,677 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 10:38:50,677 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 10:38:50,677 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 10:38:50,678 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 10:38:50,678 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 10:43:50,682 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 10:43:50,689 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 10:43:50,691 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 10:43:50,691 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 10:43:50,691 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 10:43:50,691 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 10:43:50,691 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 10:43:50,694 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 10:43:50,694 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 10:43:50,694 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 10:43:50,694 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 10:43:50,694 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 10:43:50,694 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 10:43:50,695 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 10:43:50,695 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 10:43:50,696 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 10:43:50,696 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 10:43:50,696 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 10:48:50,700 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 10:48:50,707 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 10:48:50,709 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 10:48:50,709 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 10:48:50,709 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 10:48:50,709 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 10:48:50,709 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 10:48:50,712 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 10:48:50,712 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 10:48:50,712 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 10:48:50,712 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 10:48:50,712 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 10:48:50,713 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 10:48:50,713 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 10:48:50,714 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 10:48:50,714 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 10:48:50,714 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 10:48:50,714 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 10:53:50,718 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 10:53:50,725 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 10:53:50,726 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 10:53:50,727 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 10:53:50,727 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 10:53:50,727 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 10:53:50,727 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 10:53:50,729 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 10:53:50,729 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 10:53:50,730 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 10:53:50,730 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 10:53:50,730 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 10:53:50,730 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 10:53:50,731 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 10:53:50,731 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 10:53:50,731 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 10:53:50,732 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 10:53:50,732 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 10:58:50,735 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 10:58:50,743 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 10:58:50,745 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 10:58:50,745 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 10:58:50,745 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 10:58:50,745 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 10:58:50,745 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 10:58:50,747 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 10:58:50,748 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 10:58:50,748 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 10:58:50,748 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 10:58:50,748 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 10:58:50,748 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 10:58:50,749 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 10:58:50,749 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 10:58:50,749 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 10:58:50,750 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 10:58:50,750 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 11:03:50,753 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 11:03:50,760 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 11:03:50,762 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 11:03:50,762 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 11:03:50,762 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 11:03:50,762 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 11:03:50,763 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 11:03:50,765 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 11:03:50,765 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 11:03:50,765 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 11:03:50,765 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 11:03:50,766 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 11:03:50,766 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 11:03:50,766 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 11:03:50,767 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 11:03:50,767 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 11:03:50,767 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 11:03:50,767 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 11:08:50,771 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 11:08:50,778 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 11:08:50,780 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 11:08:50,780 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 11:08:50,780 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 11:08:50,780 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 11:08:50,781 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 11:08:50,783 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 11:08:50,783 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 11:08:50,783 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 11:08:50,783 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 11:08:50,784 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 11:08:50,784 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 11:08:50,785 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 11:08:50,785 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 11:08:50,785 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 11:08:50,785 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 11:08:50,785 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 11:13:50,789 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 11:13:50,796 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 11:13:50,844 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 11:13:50,844 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 11:13:50,844 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 11:13:50,844 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 11:13:50,844 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 11:13:50,846 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 11:13:50,846 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 11:13:50,846 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 11:13:50,846 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 11:13:50,846 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 11:13:50,846 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 11:13:50,847 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 11:13:50,847 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 11:13:50,847 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 11:13:50,847 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 11:13:50,848 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 11:18:50,851 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 11:18:50,858 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 11:18:50,860 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 11:18:50,860 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 11:18:50,860 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 11:18:50,860 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 11:18:50,860 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 11:18:50,863 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 11:18:50,863 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 11:18:50,863 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 11:18:50,863 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 11:18:50,863 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 11:18:50,863 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 11:18:50,864 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 11:18:50,864 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 11:18:50,865 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 11:18:50,865 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 11:18:50,865 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 11:23:50,868 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 11:23:50,876 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 11:23:50,878 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 11:23:50,878 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 11:23:50,878 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 11:23:50,878 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 11:23:50,878 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 11:23:50,880 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 11:23:50,880 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 11:23:50,881 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 11:23:50,881 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 11:23:50,881 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 11:23:50,881 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 11:23:50,882 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 11:23:50,882 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 11:23:50,882 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 11:23:50,883 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 11:23:50,883 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 11:28:50,886 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 11:28:50,893 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 11:28:50,895 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 11:28:50,895 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 11:28:50,896 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 11:28:50,896 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 11:28:50,896 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 11:28:50,898 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 11:28:50,898 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 11:28:50,898 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 11:28:50,899 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 11:28:50,899 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 11:28:50,899 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 11:28:50,900 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 11:28:50,900 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 11:28:50,900 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 11:28:50,900 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 11:28:50,901 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 11:33:50,904 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 11:33:50,911 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 11:33:50,913 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 11:33:50,913 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 11:33:50,913 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 11:33:50,914 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 11:33:50,914 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 11:33:50,916 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 11:33:50,916 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 11:33:50,916 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 11:33:50,916 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 11:33:50,917 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 11:33:50,917 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 11:33:50,918 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 11:33:50,918 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 11:33:50,918 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 11:33:50,918 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 11:33:50,919 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 11:38:50,922 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 11:38:50,929 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 11:38:50,931 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 11:38:50,931 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 11:38:50,932 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 11:38:50,932 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 11:38:50,932 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 11:38:50,934 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 11:38:50,934 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 11:38:50,934 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 11:38:50,934 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 11:38:50,935 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 11:38:50,935 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 11:38:50,936 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 11:38:50,936 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 11:38:50,936 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 11:38:50,936 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 11:38:50,937 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 11:43:50,940 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 11:43:50,947 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 11:43:50,949 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 11:43:50,949 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 11:43:50,949 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 11:43:50,949 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 11:43:50,949 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 11:43:50,952 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 11:43:50,952 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 11:43:50,952 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 11:43:50,952 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 11:43:50,952 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 11:43:50,953 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 11:43:50,953 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 11:43:50,954 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 11:43:50,954 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 11:43:50,954 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 11:43:50,954 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 11:48:50,958 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 11:48:50,968 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 11:48:50,970 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 11:48:50,970 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 11:48:50,970 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 11:48:50,970 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 11:48:50,970 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 11:48:50,973 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 11:48:50,973 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 11:48:50,973 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 11:48:50,973 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 11:48:50,973 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 11:48:50,973 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 11:48:50,974 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 11:48:50,974 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 11:48:50,975 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 11:48:50,975 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 11:48:50,975 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 11:53:50,979 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 11:53:50,986 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 11:53:50,988 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 11:53:50,988 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 11:53:50,988 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 11:53:50,988 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 11:53:50,988 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 11:53:50,990 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 11:53:50,991 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 11:53:50,991 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 11:53:50,991 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 11:53:50,991 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 11:53:50,991 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 11:53:50,992 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 11:53:50,992 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 11:53:50,993 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 11:53:50,993 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 11:53:50,993 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 11:58:50,996 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 11:58:51,004 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 11:58:51,006 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 11:58:51,006 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 11:58:51,006 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 11:58:51,006 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 11:58:51,006 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 11:58:51,008 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 11:58:51,009 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 11:58:51,009 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 11:58:51,009 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 11:58:51,009 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 11:58:51,009 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 11:58:51,010 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 11:58:51,010 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 11:58:51,010 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 11:58:51,011 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 11:58:51,011 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 12:03:51,015 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 12:03:51,022 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 12:03:51,024 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 12:03:51,024 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 12:03:51,024 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 12:03:51,024 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 12:03:51,024 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 12:03:51,027 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 12:03:51,027 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 12:03:51,027 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 12:03:51,027 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 12:03:51,027 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 12:03:51,027 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 12:03:51,028 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 12:03:51,028 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 12:03:51,029 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 12:03:51,029 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 12:03:51,029 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 12:08:51,032 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 12:08:51,040 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 12:08:51,042 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 12:08:51,042 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 12:08:51,042 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 12:08:51,042 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 12:08:51,042 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 12:08:51,045 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 12:08:51,045 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 12:08:51,045 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 12:08:51,045 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 12:08:51,045 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 12:08:51,045 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 12:08:51,046 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 12:08:51,046 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 12:08:51,047 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 12:08:51,047 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 12:08:51,047 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 12:13:51,050 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 12:13:51,058 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 12:13:51,059 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 12:13:51,059 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 12:13:51,060 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 12:13:51,060 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 12:13:51,060 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 12:13:51,062 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 12:13:51,062 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 12:13:51,062 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 12:13:51,063 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 12:13:51,063 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 12:13:51,063 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 12:13:51,064 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 12:13:51,064 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 12:13:51,064 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 12:13:51,064 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 12:13:51,065 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 12:18:51,068 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 12:18:51,076 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 12:18:51,078 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 12:18:51,078 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 12:18:51,078 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 12:18:51,078 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 12:18:51,078 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 12:18:51,080 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 12:18:51,081 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 12:18:51,081 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 12:18:51,081 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 12:18:51,081 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 12:18:51,081 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 12:18:51,082 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 12:18:51,082 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 12:18:51,082 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 12:18:51,083 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 12:18:51,083 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 12:23:51,087 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 12:23:51,094 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 12:23:51,096 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 12:23:51,096 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 12:23:51,096 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 12:23:51,096 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 12:23:51,096 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 12:23:51,099 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 12:23:51,099 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 12:23:51,099 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 12:23:51,099 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 12:23:51,100 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 12:23:51,100 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 12:23:51,101 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 12:23:51,101 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 12:23:51,101 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 12:23:51,101 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 12:23:51,102 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 12:28:51,105 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 12:28:51,112 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 12:28:51,114 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 12:28:51,114 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 12:28:51,114 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 12:28:51,114 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 12:28:51,114 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 12:28:51,117 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 12:28:51,117 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 12:28:51,117 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 12:28:51,117 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 12:28:51,117 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 12:28:51,117 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 12:28:51,118 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 12:28:51,118 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 12:28:51,119 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 12:28:51,119 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 12:28:51,119 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 12:33:51,123 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 12:33:51,130 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 12:33:51,132 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 12:33:51,132 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 12:33:51,132 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 12:33:51,132 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 12:33:51,132 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 12:33:51,134 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 12:33:51,135 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 12:33:51,135 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 12:33:51,135 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 12:33:51,135 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 12:33:51,135 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 12:33:51,136 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 12:33:51,136 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 12:33:51,136 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 12:33:51,137 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 12:33:51,137 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 12:38:51,140 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 12:38:51,147 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 12:38:51,149 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 12:38:51,149 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 12:38:51,149 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 12:38:51,149 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 12:38:51,149 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 12:38:51,197 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 12:38:51,198 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 12:38:51,198 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 12:38:51,198 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 12:38:51,198 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 12:38:51,198 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 12:38:51,199 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 12:38:51,199 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 12:38:51,199 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 12:38:51,199 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 12:38:51,199 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 12:43:51,202 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 12:43:51,210 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 12:43:51,211 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 12:43:51,211 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 12:43:51,211 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 12:43:51,212 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 12:43:51,212 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 12:43:51,214 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 12:43:51,214 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 12:43:51,214 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 12:43:51,215 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 12:43:51,215 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 12:43:51,215 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 12:43:51,216 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 12:43:51,216 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 12:43:51,216 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 12:43:51,216 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 12:43:51,217 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 12:48:51,220 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 12:48:51,227 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 12:48:51,229 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 12:48:51,229 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 12:48:51,229 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 12:48:51,229 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 12:48:51,229 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 12:48:51,231 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 12:48:51,232 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 12:48:51,232 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 12:48:51,232 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 12:48:51,232 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 12:48:51,232 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 12:48:51,233 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 12:48:51,233 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 12:48:51,233 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 12:48:51,234 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 12:48:51,234 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 12:53:51,237 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 12:53:51,245 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 12:53:51,247 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 12:53:51,247 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 12:53:51,247 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 12:53:51,247 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 12:53:51,247 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 12:53:51,249 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 12:53:51,250 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 12:53:51,250 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 12:53:51,250 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 12:53:51,250 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 12:53:51,250 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 12:53:51,251 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 12:53:51,251 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 12:53:51,251 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 12:53:51,252 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 12:53:51,252 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 12:58:51,256 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 12:58:51,264 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 12:58:51,265 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 12:58:51,266 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 12:58:51,266 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 12:58:51,266 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 12:58:51,266 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 12:58:51,268 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 12:58:51,268 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 12:58:51,269 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 12:58:51,269 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 12:58:51,269 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 12:58:51,269 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 12:58:51,270 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 12:58:51,270 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 12:58:51,270 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 12:58:51,270 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 12:58:51,271 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 13:03:51,274 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 13:03:51,281 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 13:03:51,283 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 13:03:51,283 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 13:03:51,283 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 13:03:51,284 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 13:03:51,284 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 13:03:51,286 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 13:03:51,286 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 13:03:51,286 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 13:03:51,286 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 13:03:51,287 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 13:03:51,287 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 13:03:51,287 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 13:03:51,288 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 13:03:51,288 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 13:03:51,288 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 13:03:51,288 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 13:08:51,292 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 13:08:51,299 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 13:08:51,301 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 13:08:51,301 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 13:08:51,301 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 13:08:51,301 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 13:08:51,301 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 13:08:51,303 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 13:08:51,304 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 13:08:51,304 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 13:08:51,304 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 13:08:51,304 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 13:08:51,304 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 13:08:51,305 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 13:08:51,305 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 13:08:51,305 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 13:08:51,306 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 13:08:51,306 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 13:13:51,309 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 13:13:51,317 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 13:13:51,318 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 13:13:51,319 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 13:13:51,319 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 13:13:51,319 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 13:13:51,319 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 13:13:51,321 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 13:13:51,321 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 13:13:51,321 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 13:13:51,322 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 13:13:51,322 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 13:13:51,322 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 13:13:51,323 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 13:13:51,323 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 13:13:51,323 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 13:13:51,324 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 13:13:51,324 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 13:18:51,327 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 13:18:51,351 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 13:18:51,353 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 13:18:51,353 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 13:18:51,353 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 13:18:51,353 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 13:18:51,353 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 13:18:51,355 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 13:18:51,356 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 13:18:51,356 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 13:18:51,356 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 13:18:51,356 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 13:18:51,356 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 13:18:51,357 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 13:18:51,357 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 13:18:51,357 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 13:18:51,358 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 13:18:51,358 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 13:23:51,362 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 13:23:51,378 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 13:23:51,379 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 13:23:51,380 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 13:23:51,380 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 13:23:51,380 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 13:23:51,380 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 13:23:51,382 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 13:23:51,382 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 13:23:51,382 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 13:23:51,382 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 13:23:51,382 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 13:23:51,382 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 13:23:51,383 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 13:23:51,383 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 13:23:51,383 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 13:23:51,383 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 13:23:51,383 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 13:28:51,386 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 13:28:51,394 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 13:28:51,396 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 13:28:51,396 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 13:28:51,396 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 13:28:51,396 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 13:28:51,396 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 13:28:51,398 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 13:28:51,398 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 13:28:51,399 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 13:28:51,399 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 13:28:51,399 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 13:28:51,399 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 13:28:51,400 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 13:28:51,400 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 13:28:51,400 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 13:28:51,400 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 13:28:51,401 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 13:33:51,406 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 13:33:51,414 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 13:33:51,416 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 13:33:51,416 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 13:33:51,416 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 13:33:51,416 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 13:33:51,416 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 13:33:51,419 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 13:33:51,419 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 13:33:51,419 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 13:33:51,419 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 13:33:51,419 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 13:33:51,419 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 13:33:51,420 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 13:33:51,421 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 13:33:51,421 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 13:33:51,421 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 13:33:51,421 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 13:38:51,425 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 13:38:51,432 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 13:38:51,434 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 13:38:51,434 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 13:38:51,434 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 13:38:51,435 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 13:38:51,435 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 13:38:51,437 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 13:38:51,437 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 13:38:51,437 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 13:38:51,438 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 13:38:51,438 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 13:38:51,438 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 13:38:51,439 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 13:38:51,439 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 13:38:51,439 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 13:38:51,439 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 13:38:51,440 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 13:43:51,444 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 13:43:51,451 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 13:43:51,452 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 13:43:51,452 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 13:43:51,452 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 13:43:51,452 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 13:43:51,452 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 13:43:51,454 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 13:43:51,454 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 13:43:51,454 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 13:43:51,454 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 13:43:51,454 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 13:43:51,454 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 13:43:51,455 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 13:43:51,455 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 13:43:51,455 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 13:43:51,456 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 13:43:51,456 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 13:48:51,460 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 13:48:51,476 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 13:48:51,478 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 13:48:51,478 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 13:48:51,478 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 13:48:51,478 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 13:48:51,478 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 13:48:51,480 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 13:48:51,481 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 13:48:51,481 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 13:48:51,481 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 13:48:51,481 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 13:48:51,481 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 13:48:51,482 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 13:48:51,482 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 13:48:51,482 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 13:48:51,483 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 13:48:51,483 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 13:53:51,488 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 13:53:51,505 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 13:53:51,507 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 13:53:51,507 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 13:53:51,507 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 13:53:51,507 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 13:53:51,507 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 13:53:51,509 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 13:53:51,509 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 13:53:51,509 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 13:53:51,510 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 13:53:51,510 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 13:53:51,510 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 13:53:51,511 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 13:53:51,511 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 13:53:51,511 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 13:53:51,512 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 13:53:51,512 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 13:58:51,515 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 13:58:51,523 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 13:58:51,525 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 13:58:51,525 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 13:58:51,525 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 13:58:51,525 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 13:58:51,525 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 13:58:51,527 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 13:58:51,527 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 13:58:51,528 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 13:58:51,528 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 13:58:51,528 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 13:58:51,528 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 13:58:51,529 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 13:58:51,529 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 13:58:51,529 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 13:58:51,529 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 13:58:51,530 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 14:03:51,534 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 14:03:51,543 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 14:03:51,545 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 14:03:51,545 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 14:03:51,545 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 14:03:51,546 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 14:03:51,546 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 14:03:51,594 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 14:03:51,595 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 14:03:51,595 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 14:03:51,595 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 14:03:51,595 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 14:03:51,595 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 14:03:51,596 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 14:03:51,596 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 14:03:51,597 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 14:03:51,597 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 14:03:51,597 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 14:08:51,601 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 14:08:51,609 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 14:08:51,611 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 14:08:51,611 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 14:08:51,611 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 14:08:51,611 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 14:08:51,611 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 14:08:51,614 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 14:08:51,614 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 14:08:51,614 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 14:08:51,614 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 14:08:51,614 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 14:08:51,614 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 14:08:51,615 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 14:08:51,615 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 14:08:51,616 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 14:08:51,616 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 14:08:51,616 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 14:13:51,620 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 14:13:51,636 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 14:13:51,638 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 14:13:51,638 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 14:13:51,638 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 14:13:51,638 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 14:13:51,638 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 14:13:51,641 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 14:13:51,641 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 14:13:51,641 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 14:13:51,641 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 14:13:51,641 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 14:13:51,641 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 14:13:51,642 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 14:13:51,642 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 14:13:51,643 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 14:13:51,643 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 14:13:51,643 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 14:18:51,646 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 14:18:51,654 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 14:18:51,655 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 14:18:51,655 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 14:18:51,656 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 14:18:51,656 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 14:18:51,656 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 14:18:51,658 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 14:18:51,658 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 14:18:51,658 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 14:18:51,659 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 14:18:51,659 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 14:18:51,659 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 14:18:51,660 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 14:18:51,660 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 14:18:51,660 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 14:18:51,660 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 14:18:51,661 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 14:23:51,665 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 14:23:51,673 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 14:23:51,675 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 14:23:51,675 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 14:23:51,675 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 14:23:51,675 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 14:23:51,675 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 14:23:51,677 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 14:23:51,677 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 14:23:51,677 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 14:23:51,678 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 14:23:51,678 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 14:23:51,678 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 14:23:51,679 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 14:23:51,679 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 14:23:51,679 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 14:23:51,679 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 14:23:51,680 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 14:28:51,683 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 14:28:51,690 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 14:28:51,692 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 14:28:51,693 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 14:28:51,693 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 14:28:51,693 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 14:28:51,693 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 14:28:51,695 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 14:28:51,695 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 14:28:51,695 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 14:28:51,695 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 14:28:51,696 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 14:28:51,696 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 14:28:51,697 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 14:28:51,697 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 14:28:51,697 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 14:28:51,697 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 14:28:51,697 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 14:33:51,702 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 14:33:51,709 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 14:33:51,711 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 14:33:51,711 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 14:33:51,711 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 14:33:51,711 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 14:33:51,711 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 14:33:51,714 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 14:33:51,714 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 14:33:51,714 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 14:33:51,714 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 14:33:51,714 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 14:33:51,715 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 14:33:51,715 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 14:33:51,716 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 14:33:51,716 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 14:33:51,716 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 14:33:51,716 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 14:38:51,720 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 14:38:51,727 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 14:38:51,729 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 14:38:51,729 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 14:38:51,729 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 14:38:51,729 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 14:38:51,729 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 14:38:51,731 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 14:38:51,732 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 14:38:51,732 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 14:38:51,732 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 14:38:51,732 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 14:38:51,732 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 14:38:51,733 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 14:38:51,733 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 14:38:51,733 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 14:38:51,734 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 14:38:51,734 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 14:43:51,739 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 14:43:51,747 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 14:43:51,749 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 14:43:51,749 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 14:43:51,749 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 14:43:51,749 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 14:43:51,749 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 14:43:51,752 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 14:43:51,752 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 14:43:51,752 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 14:43:51,752 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 14:43:51,752 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 14:43:51,752 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 14:43:51,753 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 14:43:51,753 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 14:43:51,754 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 14:43:51,754 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 14:43:51,754 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 14:48:51,757 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 14:48:51,764 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 14:48:51,766 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 14:48:51,766 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 14:48:51,766 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 14:48:51,766 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 14:48:51,766 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 14:48:51,769 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 14:48:51,769 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 14:48:51,769 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 14:48:51,769 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 14:48:51,769 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 14:48:51,769 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 14:48:51,770 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 14:48:51,771 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 14:48:51,771 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 14:48:51,771 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 14:48:51,771 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 14:53:51,776 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 14:53:51,783 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 14:53:51,805 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 14:53:51,805 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 14:53:51,805 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 14:53:51,805 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 14:53:51,805 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 14:53:51,807 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 14:53:51,807 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 14:53:51,808 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 14:53:51,808 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 14:53:51,808 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 14:53:51,808 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 14:53:51,808 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 14:53:51,809 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 14:53:51,809 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 14:53:51,809 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 14:53:51,809 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 14:58:51,812 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of transactions: 0 Total time for transactions(ms): 0Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
2015-01-06 14:58:51,821 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file fsimage size 110 bytes.
2015-01-06 14:58:51,823 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Downloaded file edits size 4 bytes.
2015-01-06 14:58:51,823 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2015-01-06 14:58:51,823 INFO org.apache.hadoop.hdfs.util.GSet: 2% max memory = 18.21 MB
2015-01-06 14:58:51,823 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2015-01-06 14:58:51,823 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2015-01-06 14:58:51,826 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=imdb
2015-01-06 14:58:51,826 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2015-01-06 14:58:51,826 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=false
2015-01-06 14:58:51,826 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2015-01-06 14:58:51,826 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2015-01-06 14:58:51,826 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2015-01-06 14:58:51,827 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2015-01-06 14:58:51,827 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2015-01-06 14:58:51,828 INFO org.apache.hadoop.hdfs.server.common.Storage: Edits file /home/imdb/hadoop/tmp/dfs/namesecondary/current/edits of size 4 edits # 0 loaded in 0 seconds.
2015-01-06 14:58:51,828 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 14:58:51,828 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.io.IOException: Inconsistent checkpoint fileds. LV = -32 namespaceID = 428516640 cTime = 0. Expecting respectively: -32; 1664173314; 0
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:66)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:673)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$500(SecondaryNameNode.java:571)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:448)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:312)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)

2015-01-06 15:03:52,840 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 15:03:53,841 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 15:03:54,841 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 15:03:55,842 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 15:03:56,843 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 15:03:57,844 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 15:03:58,844 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 15:03:59,845 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 15:04:00,846 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 15:04:01,846 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 15:04:01,847 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 15:04:01,848 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 15:09:02,860 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 15:09:03,860 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 15:09:04,861 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 15:09:05,862 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 15:09:06,862 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 15:09:07,863 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 15:09:08,864 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 15:09:09,864 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 15:09:10,865 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 15:09:11,866 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 15:09:11,867 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 15:09:11,867 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 15:14:12,871 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 15:14:13,872 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 15:14:14,872 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 15:14:15,873 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 15:14:16,874 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 15:14:17,874 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 15:14:18,875 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 15:14:19,876 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 15:14:20,877 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 15:14:21,877 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 15:14:21,878 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 15:14:21,879 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 15:19:22,883 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 15:19:23,883 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 15:19:24,884 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 15:19:25,885 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 15:19:26,885 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 15:19:27,886 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 15:19:28,887 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 15:19:29,887 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 15:19:30,888 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 15:19:31,889 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 15:19:31,889 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 15:19:31,890 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 15:24:32,893 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 15:24:33,894 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 15:24:34,894 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 15:24:35,895 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 15:24:36,896 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 15:24:37,897 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 15:24:38,897 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 15:24:39,898 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 15:24:40,899 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 15:24:41,899 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 15:24:41,900 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 15:24:41,900 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 15:29:42,913 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 15:29:43,914 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 15:29:44,914 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 15:29:45,915 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 15:29:46,916 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 15:29:47,916 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 15:29:48,917 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 15:29:49,918 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 15:29:50,918 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 15:29:51,919 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 15:29:51,920 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 15:29:51,920 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 15:34:52,924 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 15:34:53,925 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 15:34:54,926 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 15:34:55,926 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 15:34:56,927 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 15:34:57,928 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 15:34:58,929 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 15:34:59,930 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 15:35:00,930 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 15:35:01,931 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 15:35:01,932 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 15:35:01,932 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 15:40:02,936 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 15:40:03,937 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 15:40:04,938 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 15:40:05,939 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 15:40:06,939 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 15:40:07,940 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 15:40:08,941 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 15:40:09,941 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 15:40:10,942 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 15:40:11,943 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 15:40:11,943 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 15:40:11,944 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 15:45:12,948 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 15:45:13,949 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 15:45:14,949 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 15:45:15,950 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 15:45:16,951 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 15:45:17,951 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 15:45:18,952 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 15:45:19,953 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 15:45:20,953 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 15:45:21,954 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 15:45:21,955 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 15:45:21,955 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 15:50:22,967 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 15:50:23,968 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 15:50:24,969 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 15:50:25,969 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 15:50:26,970 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 15:50:27,971 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 15:50:28,971 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 15:50:29,972 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 15:50:30,973 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 15:50:31,974 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 15:50:31,974 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 15:50:31,975 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 15:55:32,978 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 15:55:33,979 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 15:55:34,980 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 15:55:35,981 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 15:55:36,981 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 15:55:37,982 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 15:55:38,983 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 15:55:39,983 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 15:55:40,984 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 15:55:41,985 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 15:55:41,985 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 15:55:41,986 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 16:00:42,989 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 16:00:43,989 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 16:00:44,990 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 16:00:45,991 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 16:00:46,992 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 16:00:47,992 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 16:00:48,993 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 16:00:49,994 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 16:00:50,994 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 16:00:51,995 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 16:00:51,996 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 16:00:51,996 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 16:05:52,999 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 16:05:54,000 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 16:05:55,001 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 16:05:56,001 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 16:05:57,002 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 16:05:58,003 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 16:05:59,003 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 16:06:00,004 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 16:06:01,005 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 16:06:02,005 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 16:06:02,006 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 16:06:02,007 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 16:11:03,018 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 16:11:04,019 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 16:11:05,020 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 16:11:06,021 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 16:11:07,022 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 16:11:08,022 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 16:11:09,023 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 16:11:10,024 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 16:11:11,024 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 16:11:12,025 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 16:11:12,026 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 16:11:12,026 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 16:16:13,030 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 16:16:14,031 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 16:16:15,032 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 16:16:16,032 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 16:16:17,033 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 16:16:18,034 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 16:16:19,034 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 16:16:20,035 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 16:16:21,036 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 16:16:22,036 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 16:16:22,037 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 16:16:22,038 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 16:21:23,041 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 16:21:24,041 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 16:21:25,042 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 16:21:26,043 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 16:21:27,044 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 16:21:28,044 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 16:21:29,045 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 16:21:30,046 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 16:21:31,046 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 16:21:32,047 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 16:21:32,048 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 16:21:32,048 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 16:26:33,051 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 16:26:34,052 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 16:26:35,053 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 16:26:36,054 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 16:26:37,054 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 16:26:38,055 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 16:26:39,056 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 16:26:40,056 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 16:26:41,057 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 16:26:42,058 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 16:26:42,059 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 16:26:42,060 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 16:31:43,063 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 16:31:44,064 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 16:31:45,064 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 16:31:46,065 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 16:31:47,066 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 16:31:48,067 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 16:31:49,067 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 16:31:50,068 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 16:31:51,069 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 16:31:52,069 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 16:31:52,070 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 16:31:52,071 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 16:36:53,074 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 16:36:54,075 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 16:36:55,075 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 16:36:56,076 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 16:36:57,077 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 16:36:58,078 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 16:36:59,078 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 16:37:00,079 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 16:37:01,080 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 16:37:02,080 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 16:37:02,081 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 16:37:02,082 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 16:42:03,085 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 16:42:04,085 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 16:42:05,086 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 16:42:06,087 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 16:42:07,088 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 16:42:08,088 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 16:42:09,089 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 16:42:10,090 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 16:42:11,090 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 16:42:12,091 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 16:42:12,092 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 16:42:12,093 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 16:47:13,096 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 16:47:14,097 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 16:47:15,097 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 16:47:16,098 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 16:47:17,099 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 16:47:18,100 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 16:47:19,101 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 16:47:20,101 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 16:47:21,102 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 16:47:22,103 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 16:47:22,103 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 16:47:22,104 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 16:52:23,107 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 16:52:24,108 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 16:52:25,108 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 16:52:26,109 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 16:52:27,110 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 16:52:28,110 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 16:52:29,111 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 16:52:30,112 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 16:52:31,112 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 16:52:32,113 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 16:52:32,114 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 16:52:32,114 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 16:57:33,117 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 16:57:34,118 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 16:57:35,119 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 16:57:36,119 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 16:57:37,120 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 16:57:38,121 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 16:57:39,121 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 16:57:40,122 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 16:57:41,123 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 16:57:42,123 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 16:57:42,124 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 16:57:42,125 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 17:02:43,128 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 17:02:44,128 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 17:02:45,129 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 17:02:46,130 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 17:02:47,131 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 17:02:48,131 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 17:02:49,132 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 17:02:50,133 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 17:02:51,133 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 17:02:52,134 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 17:02:52,135 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 17:02:52,136 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 17:07:53,139 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 17:07:54,140 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 17:07:55,141 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 17:07:56,141 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 17:07:57,142 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 17:07:58,143 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 17:07:59,143 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 17:08:00,144 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 17:08:01,145 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 17:08:02,145 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 17:08:02,146 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 17:08:02,147 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 17:13:03,150 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 17:13:04,151 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 17:13:05,151 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 17:13:06,152 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 17:13:07,153 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 17:13:08,153 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 17:13:09,154 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 17:13:10,155 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 17:13:11,155 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 17:13:12,156 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 17:13:12,157 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 17:13:12,157 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 17:18:13,161 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 17:18:14,161 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 17:18:15,162 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 17:18:16,163 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 17:18:17,164 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 17:18:18,164 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 17:18:19,165 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 17:18:20,166 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 17:18:21,167 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 17:18:22,167 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 17:18:22,168 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 17:18:22,168 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 17:23:23,171 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 17:23:24,172 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 17:23:25,173 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 17:23:26,174 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 17:23:27,174 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 17:23:28,175 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 17:23:29,176 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 17:23:30,176 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 17:23:31,177 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 17:23:32,178 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 17:23:32,179 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 17:23:32,179 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 17:28:33,182 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 17:28:34,183 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 17:28:35,184 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 17:28:36,184 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 17:28:37,185 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 17:28:38,186 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 17:28:39,186 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 17:28:40,187 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 17:28:41,188 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 17:28:42,188 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 17:28:42,189 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 17:28:42,190 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 17:33:43,203 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 17:33:44,204 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 17:33:45,205 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 17:33:46,206 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 17:33:47,207 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 17:33:48,208 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 17:33:49,208 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 17:33:50,209 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 17:33:51,210 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 17:33:52,210 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 17:33:52,211 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 17:33:52,212 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 17:38:53,227 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 17:38:54,228 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 17:38:55,228 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 17:38:56,229 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 17:38:57,230 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 17:38:58,231 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 17:38:59,232 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 17:39:00,232 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 17:39:01,233 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 17:39:02,234 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 17:39:02,235 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 17:39:02,235 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 17:44:03,239 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 17:44:04,240 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 17:44:05,241 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 17:44:06,242 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 17:44:07,242 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 17:44:08,243 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 17:44:09,244 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 17:44:10,245 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 17:44:11,245 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 17:44:12,246 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 17:44:12,247 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 17:44:12,247 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 17:49:13,261 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 17:49:14,262 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 17:49:15,263 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 17:49:16,263 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 17:49:17,264 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 17:49:18,265 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 17:49:19,266 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 17:49:20,266 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 17:49:21,267 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 17:49:22,268 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 17:49:22,268 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 17:49:22,269 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 17:54:23,273 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 17:54:24,274 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 17:54:25,275 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 17:54:26,275 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 17:54:27,276 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 17:54:28,277 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 17:54:29,278 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 17:54:30,279 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 17:54:31,279 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 17:54:32,280 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 17:54:32,281 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 17:54:32,281 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 17:59:33,295 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 17:59:34,295 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 17:59:35,296 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 17:59:36,297 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 17:59:37,298 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 17:59:38,298 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 17:59:39,299 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 17:59:40,300 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 17:59:41,300 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 17:59:42,301 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 17:59:42,302 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 17:59:42,302 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 18:04:43,306 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 18:04:44,307 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 18:04:45,308 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 18:04:46,309 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 18:04:47,309 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 18:04:48,310 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 18:04:49,311 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 18:04:50,311 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 18:04:51,312 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 18:04:52,313 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 18:04:52,314 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 18:04:52,314 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 18:09:53,317 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 18:09:54,318 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 18:09:55,318 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 18:09:56,319 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 18:09:57,320 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 18:09:58,321 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 18:09:59,321 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 18:10:00,322 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 18:10:01,323 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 18:10:02,324 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 18:10:02,325 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 18:10:02,326 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 18:15:03,328 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 18:15:04,329 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 18:15:05,330 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 18:15:06,331 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 18:15:07,331 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 18:15:08,332 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 18:15:09,333 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 18:15:10,333 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 18:15:11,334 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 18:15:12,335 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 18:15:12,336 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 18:15:12,336 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 18:20:13,340 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 18:20:14,341 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 18:20:15,342 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 18:20:16,343 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 18:20:17,344 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 18:20:18,344 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 18:20:19,345 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 18:20:20,346 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 18:20:21,347 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 18:20:22,347 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 18:20:22,348 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 18:20:22,349 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 18:25:23,353 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 18:25:24,354 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 18:25:25,355 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 18:25:26,355 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 18:25:27,356 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 18:25:28,357 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 18:25:29,358 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 18:25:30,359 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 18:25:31,360 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 18:25:32,360 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 18:25:32,361 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 18:25:32,362 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 18:30:33,365 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 18:30:34,366 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 18:30:35,367 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 18:30:36,367 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 18:30:37,368 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 18:30:38,369 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 18:30:39,370 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 18:30:40,370 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 18:30:41,371 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 18:30:42,372 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 18:30:42,372 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 18:30:42,373 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 18:35:43,376 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 18:35:44,377 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 18:35:45,378 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 18:35:46,379 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 18:35:47,379 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 18:35:48,380 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 18:35:49,381 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 18:35:50,381 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 18:35:51,383 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 18:35:52,383 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 18:35:52,384 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 18:35:52,385 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 18:40:53,396 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 18:40:54,397 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 18:40:55,398 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 18:40:56,399 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 18:40:57,400 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 18:40:58,400 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 18:40:59,401 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 18:41:00,402 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 18:41:01,403 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 18:41:02,403 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 18:41:02,404 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 18:41:02,405 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 18:46:03,408 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 18:46:04,409 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 18:46:05,409 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 18:46:06,410 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 18:46:07,411 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 18:46:08,411 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 18:46:09,412 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 18:46:10,413 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 18:46:11,413 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 18:46:12,414 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 18:46:12,415 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 18:46:12,415 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 18:51:13,418 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 18:51:14,419 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 18:51:15,420 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 18:51:16,420 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 18:51:17,421 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 18:51:18,422 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 18:51:19,423 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 18:51:20,423 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 18:51:21,424 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 18:51:22,425 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 18:51:22,425 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 18:51:22,426 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 18:56:23,429 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 18:56:24,430 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 18:56:25,430 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 18:56:26,431 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 18:56:27,432 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 18:56:28,433 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 18:56:29,434 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 18:56:30,434 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 18:56:31,435 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 18:56:32,436 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 18:56:32,436 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 18:56:32,437 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 19:01:33,441 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 19:01:34,441 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 19:01:35,442 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 19:01:36,443 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 19:01:37,443 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 19:01:38,444 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 19:01:39,445 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 19:01:40,446 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 19:01:41,446 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 19:01:42,447 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 19:01:42,448 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 19:01:42,448 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 19:06:43,451 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 19:06:44,452 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 19:06:45,453 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 19:06:46,453 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 19:06:47,454 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 19:06:48,455 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 19:06:49,456 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 19:06:50,456 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 19:06:51,457 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 19:06:52,458 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 19:06:52,458 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 19:06:52,459 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 19:11:53,462 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 19:11:54,463 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 19:11:55,464 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 19:11:56,465 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 19:11:57,465 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 19:11:58,466 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 19:11:59,467 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 19:12:00,467 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 19:12:01,468 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 19:12:02,469 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 19:12:02,470 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 19:12:02,470 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 19:17:03,473 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 19:17:04,474 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 19:17:05,475 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 19:17:06,476 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 19:17:07,476 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 19:17:08,477 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 19:17:09,478 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 19:17:10,478 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 19:17:11,479 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 19:17:12,480 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 19:17:12,481 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 19:17:12,481 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 19:22:13,484 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 19:22:14,485 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 19:22:15,486 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 19:22:16,487 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 19:22:17,487 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 19:22:18,488 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 19:22:19,489 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 19:22:20,489 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 19:22:21,490 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 19:22:22,491 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 19:22:22,491 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 19:22:22,492 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 19:27:23,495 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 19:27:24,496 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 19:27:25,496 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 19:27:26,497 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 19:27:27,498 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 19:27:28,498 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 19:27:29,499 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 19:27:30,500 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 19:27:31,500 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 19:27:32,501 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 19:27:32,502 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 19:27:32,502 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 19:32:33,505 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 19:32:34,506 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 19:32:35,507 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 19:32:36,507 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 19:32:37,508 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 19:32:38,509 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 19:32:39,510 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 19:32:40,511 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 19:32:41,511 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 19:32:42,512 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 19:32:42,513 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 19:32:42,513 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 19:37:43,516 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 19:37:44,517 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 19:37:45,518 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 19:37:46,519 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 19:37:47,520 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 19:37:48,520 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 19:37:49,521 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 19:37:50,522 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 19:37:51,523 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 19:37:52,523 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 19:37:52,524 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 19:37:52,525 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 19:42:53,528 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 19:42:54,529 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 19:42:55,529 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 19:42:56,530 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 19:42:57,531 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 19:42:58,532 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 19:42:59,532 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 19:43:00,533 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 19:43:01,534 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 19:43:02,534 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 19:43:02,535 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 19:43:02,535 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 19:48:03,539 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 19:48:04,539 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 19:48:05,540 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 19:48:06,541 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 19:48:07,542 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 19:48:08,542 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 19:48:09,543 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 19:48:10,544 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 19:48:11,544 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 19:48:12,546 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 19:48:12,546 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 19:48:12,547 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 19:53:13,550 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 19:53:14,551 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 19:53:15,552 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 19:53:16,553 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 19:53:17,553 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 19:53:18,554 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 19:53:19,555 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 19:53:20,556 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 19:53:21,556 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 19:53:22,557 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 19:53:22,558 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 19:53:22,558 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 19:58:23,561 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 19:58:24,562 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 19:58:25,563 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 19:58:26,563 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 19:58:27,564 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 19:58:28,565 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 19:58:29,566 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 19:58:30,566 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 19:58:31,567 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 19:58:32,568 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 19:58:32,569 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 19:58:32,569 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 20:03:33,572 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 20:03:34,573 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 20:03:35,574 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 20:03:36,575 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 20:03:37,575 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 20:03:38,576 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 20:03:39,577 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 20:03:40,577 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 20:03:41,578 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 20:03:42,579 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 20:03:42,579 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 20:03:42,580 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 20:08:43,583 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 20:08:44,583 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 20:08:45,584 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 20:08:46,585 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 20:08:47,586 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 20:08:48,586 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 20:08:49,588 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 20:08:50,588 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 20:08:51,589 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 20:08:52,590 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 20:08:52,590 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 20:08:52,591 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 20:13:53,594 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 20:13:54,595 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 20:13:55,596 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 20:13:56,597 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 20:13:57,597 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 20:13:58,598 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 20:13:59,599 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 20:14:00,600 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 20:14:01,600 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 20:14:02,601 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 20:14:02,602 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 20:14:02,602 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 20:19:03,614 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 20:19:04,615 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 20:19:05,616 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 20:19:06,616 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 20:19:07,617 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 20:19:08,618 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 20:19:09,618 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 20:19:10,619 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 20:19:11,620 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 20:19:12,620 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 20:19:12,621 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 20:19:12,622 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 20:24:13,625 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 20:24:14,625 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 20:24:15,626 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 20:24:16,627 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 20:24:17,627 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 20:24:18,628 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 20:24:19,629 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 20:24:20,629 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 20:24:21,630 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 20:24:22,631 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 20:24:22,632 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 20:24:22,632 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 20:29:23,635 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 20:29:24,636 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 20:29:25,637 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 20:29:26,638 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 20:29:27,638 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 20:29:28,639 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 20:29:29,640 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 20:29:30,640 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 20:29:31,641 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 20:29:32,642 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 20:29:32,642 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 20:29:32,643 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 20:34:33,646 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 20:34:34,647 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 20:34:35,647 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 20:34:36,648 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 20:34:37,649 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 20:34:38,649 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 20:34:39,650 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 20:34:40,651 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 20:34:41,651 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 20:34:42,652 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 20:34:42,653 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 20:34:42,653 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 20:39:43,656 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 20:39:44,657 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 20:39:45,658 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 20:39:46,658 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 20:39:47,659 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 20:39:48,660 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 20:39:49,660 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 20:39:50,661 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 20:39:51,662 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 20:39:52,662 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 20:39:52,663 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 20:39:52,664 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 20:44:53,667 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 20:44:54,667 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 20:44:55,668 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 20:44:56,669 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 20:44:57,669 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 20:44:58,670 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 20:44:59,671 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 20:45:00,672 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 20:45:01,673 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 20:45:02,673 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 20:45:02,674 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 20:45:02,675 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 20:50:03,677 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 20:50:04,678 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 20:50:05,679 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 20:50:06,680 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 20:50:07,680 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 20:50:08,681 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 20:50:09,682 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 20:50:10,682 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 20:50:11,683 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 20:50:12,684 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 20:50:12,684 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 20:50:12,685 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 20:55:13,688 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 20:55:14,689 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 20:55:15,690 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 20:55:16,690 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 20:55:17,691 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 20:55:18,692 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 20:55:19,693 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 20:55:20,693 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 20:55:21,694 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 20:55:22,695 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 20:55:22,695 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 20:55:22,696 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 21:00:23,699 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 21:00:24,699 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 21:00:25,700 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 21:00:26,701 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 21:00:27,702 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 21:00:28,702 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 21:00:29,703 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 21:00:30,704 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 21:00:31,704 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 21:00:32,705 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 21:00:32,706 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 21:00:32,707 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 21:05:33,710 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 21:05:34,710 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 21:05:35,711 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 21:05:36,712 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 21:05:37,713 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 21:05:38,714 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 21:05:39,714 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 21:05:40,715 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 21:05:41,716 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 21:05:42,716 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 21:05:42,717 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 21:05:42,718 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 21:10:43,721 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 21:10:44,722 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 21:10:45,722 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 21:10:46,723 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 21:10:47,724 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 21:10:48,724 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 21:10:49,725 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 21:10:50,726 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 21:10:51,726 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 21:10:52,727 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 21:10:52,728 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 21:10:52,728 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 21:15:53,731 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 21:15:54,732 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 21:15:55,733 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 21:15:56,733 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 21:15:57,734 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 21:15:58,735 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 21:15:59,735 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 21:16:00,736 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 21:16:01,737 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 21:16:02,737 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 21:16:02,738 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 21:16:02,739 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 21:21:03,742 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 21:21:04,742 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 21:21:05,743 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 21:21:06,744 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 21:21:07,744 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 21:21:08,745 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 21:21:09,746 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 21:21:10,747 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 21:21:11,748 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 21:21:12,748 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 21:21:12,749 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 21:21:12,749 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 21:26:13,752 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 21:26:14,753 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 21:26:15,754 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 21:26:16,754 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 21:26:17,755 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 21:26:18,756 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 21:26:19,757 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 21:26:20,757 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 21:26:21,758 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 21:26:22,759 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 21:26:22,759 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 21:26:22,760 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 21:31:23,763 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 21:31:24,764 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 21:31:25,765 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 21:31:26,766 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 21:31:27,766 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 21:31:28,767 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 21:31:29,768 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 21:31:30,768 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 21:31:31,769 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 21:31:32,770 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 21:31:32,771 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 21:31:32,771 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 21:36:33,774 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 21:36:34,775 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 21:36:35,776 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 21:36:36,776 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 21:36:37,777 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 21:36:38,778 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 21:36:39,778 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 21:36:40,779 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 21:36:41,780 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 21:36:42,780 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 21:36:42,781 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 21:36:42,782 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 21:41:43,784 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 21:41:44,785 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 21:41:45,786 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 21:41:46,787 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 21:41:47,788 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 21:41:48,788 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 21:41:49,789 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 21:41:50,790 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 21:41:51,790 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 21:41:52,791 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 21:41:52,792 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 21:41:52,792 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 21:46:53,795 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 21:46:54,796 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 21:46:55,797 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 21:46:56,798 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 21:46:57,798 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 21:46:58,799 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 21:46:59,800 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 21:47:00,800 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 21:47:01,801 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 21:47:02,802 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 21:47:02,802 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 21:47:02,803 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 21:52:03,806 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 21:52:04,806 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 21:52:05,807 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 21:52:06,808 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 21:52:07,809 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 21:52:08,809 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 21:52:09,810 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 21:52:10,811 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 21:52:11,811 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 21:52:12,812 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 21:52:12,813 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 21:52:12,813 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 21:57:13,816 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 21:57:14,817 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 21:57:15,818 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 21:57:16,819 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 21:57:17,819 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 21:57:18,820 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 21:57:19,821 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 21:57:20,821 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 21:57:21,823 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 21:57:22,823 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 21:57:22,824 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 21:57:22,824 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 22:02:23,827 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 22:02:24,828 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 22:02:25,829 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 22:02:26,829 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 22:02:27,830 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 22:02:28,831 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 22:02:29,832 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 22:02:30,832 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 22:02:31,833 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 22:02:32,834 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 22:02:32,834 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 22:02:32,835 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 22:07:33,838 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 22:07:34,838 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 22:07:35,839 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 22:07:36,840 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 22:07:37,840 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 22:07:38,841 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 22:07:39,842 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 22:07:40,843 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 22:07:41,843 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 22:07:42,844 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 22:07:42,845 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 22:07:42,845 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 22:12:43,848 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 22:12:44,849 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 22:12:45,849 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 22:12:46,850 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 22:12:47,851 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 22:12:48,852 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 22:12:49,852 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 22:12:50,853 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 22:12:51,854 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 22:12:52,854 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 22:12:52,855 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 22:12:52,855 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 22:17:53,859 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 22:17:54,859 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 22:17:55,860 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 22:17:56,861 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 22:17:57,862 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 22:17:58,863 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 22:17:59,863 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 22:18:00,864 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 22:18:01,865 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 22:18:02,865 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 22:18:02,866 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 22:18:02,867 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 22:23:03,870 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 22:23:04,870 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 22:23:05,871 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 22:23:06,872 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 22:23:07,872 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 22:23:08,873 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 22:23:09,874 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 22:23:10,874 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 22:23:11,875 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 22:23:12,876 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 22:23:12,876 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 22:23:12,877 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 22:28:13,880 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 22:28:14,881 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 22:28:15,881 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 22:28:16,882 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 22:28:17,883 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 22:28:18,883 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 22:28:19,884 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 22:28:20,885 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 22:28:21,885 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 22:28:22,886 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 22:28:22,887 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 22:28:22,887 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 22:33:23,890 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 22:33:24,891 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 22:33:25,892 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 22:33:26,892 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 22:33:27,893 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 22:33:28,894 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 22:33:29,894 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 22:33:30,895 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 22:33:31,896 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 22:33:32,897 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 22:33:32,897 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 22:33:32,898 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 22:38:33,901 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 22:38:34,902 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 22:38:35,903 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 22:38:36,903 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 22:38:37,904 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 22:38:38,905 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 22:38:39,905 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 22:38:40,906 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 22:38:41,907 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 22:38:42,907 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 22:38:42,908 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 22:38:42,909 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 22:43:43,912 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 22:43:44,912 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 22:43:45,913 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 22:43:46,914 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 22:43:47,914 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 22:43:48,915 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 22:43:49,916 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 22:43:50,917 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 22:43:51,917 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 22:43:52,918 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 22:43:52,919 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 22:43:52,920 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 22:48:53,922 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 22:48:54,923 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 22:48:55,924 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 22:48:56,924 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 22:48:57,925 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 22:48:58,926 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 22:48:59,927 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 22:49:00,927 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 22:49:01,928 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 22:49:02,929 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 22:49:02,929 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 22:49:02,930 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 22:54:03,933 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 22:54:04,933 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 22:54:05,934 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 22:54:06,935 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 22:54:07,935 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 22:54:08,937 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 22:54:09,937 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 22:54:10,938 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 22:54:11,939 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 22:54:12,939 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 22:54:12,940 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 22:54:12,940 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 22:59:13,943 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 22:59:14,944 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 22:59:15,945 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 22:59:16,946 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 22:59:17,946 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 22:59:18,947 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 22:59:19,948 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 22:59:20,948 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 22:59:21,949 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 22:59:22,950 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 22:59:22,950 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 22:59:22,951 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 23:04:23,954 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 23:04:24,955 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 23:04:25,955 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 23:04:26,956 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 23:04:27,957 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 23:04:28,957 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 23:04:29,958 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 23:04:30,959 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 23:04:31,959 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 23:04:32,960 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 23:04:32,961 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 23:04:32,961 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 23:09:33,964 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 23:09:34,965 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 23:09:35,966 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 23:09:36,966 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 23:09:37,967 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 23:09:38,968 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 23:09:39,968 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 23:09:40,969 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 23:09:41,970 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 23:09:42,970 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 23:09:42,972 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 23:09:42,972 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 23:14:43,975 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 23:14:44,976 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 23:14:45,977 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 23:14:46,977 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 23:14:47,978 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 23:14:48,979 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 23:14:49,979 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 23:14:50,980 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 23:14:51,981 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 23:14:52,981 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 23:14:52,982 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 23:14:52,983 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 23:19:53,985 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 23:19:54,986 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 23:19:55,987 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 23:19:56,988 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 23:19:57,988 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 23:19:58,989 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 23:19:59,990 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 23:20:00,990 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 23:20:01,991 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 23:20:02,992 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 23:20:02,993 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 23:20:02,993 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 23:25:03,996 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 23:25:04,997 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 23:25:05,997 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 23:25:06,998 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 23:25:07,999 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 23:25:08,999 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 23:25:10,000 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 23:25:11,001 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 23:25:12,001 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 23:25:13,002 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 23:25:13,003 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 23:25:13,004 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 23:30:14,006 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 23:30:15,007 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 23:30:16,008 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 23:30:17,008 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 23:30:18,009 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 23:30:19,010 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 23:30:20,011 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 23:30:21,012 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 23:30:22,012 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 23:30:23,013 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 23:30:23,014 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 23:30:23,014 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 23:35:24,017 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 23:35:25,018 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 23:35:26,019 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 23:35:27,020 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 23:35:28,020 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 23:35:29,021 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 23:35:30,022 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 23:35:31,022 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 23:35:32,023 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 23:35:33,024 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 23:35:33,024 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 23:35:33,025 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 23:40:34,028 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 23:40:35,029 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 23:40:36,030 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 23:40:37,030 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 23:40:38,031 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 23:40:39,032 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 23:40:40,032 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 23:40:41,033 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 23:40:42,034 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 23:40:43,034 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 23:40:43,035 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 23:40:43,036 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 23:45:44,039 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 23:45:45,039 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 23:45:46,040 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 23:45:47,041 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 23:45:48,041 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 23:45:49,042 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 23:45:50,043 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 23:45:51,044 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 23:45:52,044 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 23:45:53,045 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 23:45:53,046 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 23:45:53,046 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 23:50:54,057 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 23:50:55,058 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 23:50:56,059 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 23:50:57,060 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 23:50:58,061 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 23:50:59,061 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 23:51:00,062 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 23:51:01,063 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 23:51:02,064 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 23:51:03,064 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 23:51:03,065 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 23:51:03,065 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

2015-01-06 23:56:04,068 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 0 time(s).
2015-01-06 23:56:05,069 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 1 time(s).
2015-01-06 23:56:06,070 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 2 time(s).
2015-01-06 23:56:07,071 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 3 time(s).
2015-01-06 23:56:08,071 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 4 time(s).
2015-01-06 23:56:09,072 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 5 time(s).
2015-01-06 23:56:10,073 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 6 time(s).
2015-01-06 23:56:11,073 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 7 time(s).
2015-01-06 23:56:12,074 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 8 time(s).
2015-01-06 23:56:13,075 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 90s192/10.11.1.192:9000. Already tried 9 time(s).
2015-01-06 23:56:13,075 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint: 
2015-01-06 23:56:13,076 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.net.ConnectException: Call to 90s192/10.11.1.192:9000 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at com.sun.proxy.$Proxy3.getEditLogSize(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:309)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:275)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 5 more

